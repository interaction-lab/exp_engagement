{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Indvidualized Participant Engagement Classifcation NN Model\n",
    "\n",
    "# ToDo/Goals: https://docs.google.com/document/d/1_dTnbdRoBV0A7xCxVEyLBdckrlsUnMnRFbbRn39tiXk/edit?usp=sharing\n",
    "# Data: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Specifiy Data Path Based on Participant/Your Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify Data Path based on participant/your computer\n",
    "# USE data from FS4 folder\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p7_data_FS4.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>of_confidence</th>\n",
       "      <th>of_success</th>\n",
       "      <th>of_gaze_0_x</th>\n",
       "      <th>of_gaze_0_y</th>\n",
       "      <th>of_gaze_0_z</th>\n",
       "      <th>of_gaze_1_x</th>\n",
       "      <th>of_gaze_1_y</th>\n",
       "      <th>of_gaze_1_z</th>\n",
       "      <th>of_gaze_angle_x</th>\n",
       "      <th>of_gaze_angle_y</th>\n",
       "      <th>...</th>\n",
       "      <th>ts_attempt</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802148</td>\n",
       "      <td>0.562868</td>\n",
       "      <td>0.109746</td>\n",
       "      <td>0.394162</td>\n",
       "      <td>0.568244</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.606309</td>\n",
       "      <td>0.508006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.553090</td>\n",
       "      <td>0.111663</td>\n",
       "      <td>0.395043</td>\n",
       "      <td>0.564921</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.607571</td>\n",
       "      <td>0.505478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802828</td>\n",
       "      <td>0.542876</td>\n",
       "      <td>0.108154</td>\n",
       "      <td>0.413679</td>\n",
       "      <td>0.556325</td>\n",
       "      <td>0.012879</td>\n",
       "      <td>0.610515</td>\n",
       "      <td>0.501938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806615</td>\n",
       "      <td>0.533710</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.390660</td>\n",
       "      <td>0.568724</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.606730</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.805455</td>\n",
       "      <td>0.529496</td>\n",
       "      <td>0.109395</td>\n",
       "      <td>0.397752</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>0.607781</td>\n",
       "      <td>0.500253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   of_confidence  of_success  of_gaze_0_x  of_gaze_0_y  of_gaze_0_z  \\\n",
       "0            1.0         1.0     0.802148     0.562868     0.109746   \n",
       "1            1.0         1.0     0.805980     0.553090     0.111663   \n",
       "2            1.0         1.0     0.802828     0.542876     0.108154   \n",
       "3            1.0         1.0     0.806615     0.533710     0.110562   \n",
       "4            1.0         1.0     0.805455     0.529496     0.109395   \n",
       "\n",
       "   of_gaze_1_x  of_gaze_1_y  of_gaze_1_z  of_gaze_angle_x  of_gaze_angle_y  \\\n",
       "0     0.394162     0.568244     0.018943         0.606309         0.508006   \n",
       "1     0.395043     0.564921     0.018227         0.607571         0.505478   \n",
       "2     0.413679     0.556325     0.012879         0.610515         0.501938   \n",
       "3     0.390660     0.568724     0.019901         0.606730         0.502613   \n",
       "4     0.397752     0.560606     0.016963         0.607781         0.500253   \n",
       "\n",
       "    ...     ts_attempt  skill_NC  skill_OS  skill_EM  diff_1  diff_2  diff_3  \\\n",
       "0   ...            0.0         0         1         0       0       1       0   \n",
       "1   ...            0.0         0         1         0       0       1       0   \n",
       "2   ...            0.0         0         1         0       0       1       0   \n",
       "3   ...            0.0         0         1         0       0       1       0   \n",
       "4   ...            0.0         0         1         0       0       1       0   \n",
       "\n",
       "   diff_4  diff_5  no_game  \n",
       "0       0       0        0  \n",
       "1       0       0        0  \n",
       "2       0       0        0  \n",
       "3       0       0        0  \n",
       "4       0       0        0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    238113\n",
      "0.0    155633\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.6047375719372388\n",
      "0 0.3952624280627613\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split (for chosen Feature Set)\n",
    "\n",
    "#### TODO: Specify which train-test split you want\n",
    "\n",
    "1. Random Shuffle Split: 70-30, 50-50, 30-70, 10-90\n",
    "2. Chronological Split: 70-30, 50-50, 30-70\n",
    "3. Session Split: 70-30, 50-50, 30-70, 10-90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Split: Train on Percentage of Data From Each Session, Sorted Chronologically \n",
    "\n",
    "def session_split(data, size):\n",
    "    sessions = data['session_num'].unique()\n",
    "    \n",
    "    first = True\n",
    "        \n",
    "    for s in sessions:\n",
    "        curr = data.loc[data['session_num'] == s]\n",
    "        curr = curr.sort_values(['timestamp'], ascending=[True])\n",
    "\n",
    "        y = curr['engagement']\n",
    "        X = curr.drop(columns=['timestamp', 'session_num', 'engagement'])\n",
    "\n",
    "        if first:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, shuffle=True)\n",
    "            first = False\n",
    "            \n",
    "        else:\n",
    "            CX_train, CX_test, Cy_train, Cy_test = train_test_split(X, y, test_size=size, shuffle=True)\n",
    "                        \n",
    "            X_train = X_train.append(CX_train)\n",
    "            X_test = X_test.append(CX_test)\n",
    "            y_train = y_train.append(Cy_train)\n",
    "            y_test = y_test.append(Cy_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data (don't need for Random Shuffle, but ok to leave it)\n",
    "\n",
    "data = data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment train-test split to run below \n",
    "\n",
    "y = data['engagement']\n",
    "X = data.drop(columns=['timestamp', 'session_num', 'engagement'])\n",
    "\n",
    "# Choose one of these \n",
    "\n",
    "\n",
    "# 1. Random Shuffle Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "### (Extra)\n",
    "# Random Shuffle Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Random Shuffle Split 30-70\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# Random Shuffle Split 10-90\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "### \n",
    "\n",
    "#############################\n",
    "\n",
    "# 2. Chronological Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# 3. Chronological Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)\n",
    "\n",
    "# 4. Chronological Split 30-70\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, shuffle=False)\n",
    "\n",
    "############################# \n",
    "\n",
    "# 5. Session Split 70-30\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.3)\n",
    "\n",
    "# 6. Session Split 50-50\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.5)\n",
    "\n",
    "# 7. Session Split 30-70\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.7)\n",
    "\n",
    "# 8. Session Split 10-90\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort X,y Train dataframes together after split \n",
    "\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Ensemble Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "118123/118123 [==============================] - 3s 23us/step - loss: 0.2589 - acc: 0.8964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2eb3cb70>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1: 64 => 32 => 16 => 1\n",
    "\n",
    "num_epochs1 = 1     \n",
    "size_batch1 = 256   \n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(units=64, input_dim=(X_train.shape[1]), kernel_initializer='glorot_normal'))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "model1.add(Dense(units=32, kernel_initializer='glorot_normal'))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "model1.add(Dense(units=16, kernel_initializer='glorot_normal'))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "model1.add(Dense(units=1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(X_train, y_train, epochs=num_epochs1, batch_size=size_batch1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "118123/118123 [==============================] - 3s 22us/step - loss: 0.6164 - acc: 0.6345\n",
      "Epoch 2/10\n",
      "118123/118123 [==============================] - 1s 10us/step - loss: 0.5405 - acc: 0.7736\n",
      "Epoch 3/10\n",
      "118123/118123 [==============================] - 1s 10us/step - loss: 0.4978 - acc: 0.7977\n",
      "Epoch 4/10\n",
      "118123/118123 [==============================] - 1s 10us/step - loss: 0.4661 - acc: 0.8257\n",
      "Epoch 5/10\n",
      "118123/118123 [==============================] - 1s 10us/step - loss: 0.4401 - acc: 0.8489\n",
      "Epoch 6/10\n",
      "118123/118123 [==============================] - 1s 11us/step - loss: 0.4182 - acc: 0.8641\n",
      "Epoch 7/10\n",
      "118123/118123 [==============================] - 1s 9us/step - loss: 0.3994 - acc: 0.8729\n",
      "Epoch 8/10\n",
      "118123/118123 [==============================] - 1s 10us/step - loss: 0.3831 - acc: 0.8797\n",
      "Epoch 9/10\n",
      "118123/118123 [==============================] - 1s 9us/step - loss: 0.3688 - acc: 0.8837\n",
      "Epoch 10/10\n",
      "118123/118123 [==============================] - 1s 9us/step - loss: 0.3562 - acc: 0.8870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3917f860>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2: 29 => 1\n",
    "\n",
    "num_epochs2 = 10       \n",
    "size_batch2 = 256   \n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(units=1, input_dim=(X_train.shape[1])))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=num_epochs2, batch_size=size_batch2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation -- Evaluate separately first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275623/275623 [==============================] - 12s 43us/step\n",
      "[0.8728077358639711, 0.726220235611687]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model1.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275623/275623 [==============================] - 10s 36us/step\n",
      "[0.512642235769102, 0.7785235629827699]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = model1.predict_proba(X_test)\n",
    "pred1 = model1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = model2.predict_proba(X_test)\n",
    "pred2 = model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197185 2978 8513 66947\n"
     ]
    }
   ],
   "source": [
    "both = 0\n",
    "mod1 = 0\n",
    "mod2 = 0\n",
    "neither = 0\n",
    "for i,v1 in enumerate(pred1):\n",
    "    v2 = pred2[i]\n",
    "    a = y_test.iloc[i]\n",
    "    \n",
    "    if (v1 == a) and (v2 == a):\n",
    "        both += 1\n",
    "    elif (v1 == a):\n",
    "        mod1 += 1\n",
    "    elif (v2 == a):\n",
    "        mod2 += 1\n",
    "    else:\n",
    "        neither += 1\n",
    "        \n",
    "print(both, mod1, mod2, neither)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571066275310842"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "208676/275623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: RECORD ACCURACY IN MODEL RESULTS SPREADSHEET\n",
    "Try to get accurracy, AUC above 90%!!!\n",
    "See results for P8 for guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC undefinied, only 1 class in test data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [275623, 181956]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-ae54505b3cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC undefinied, only 1 class in test data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 230\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [275623, 181956]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "118123/118123 [==============================] - 2s 16us/step - loss: 0.5878 - acc: 0.6926\n",
      "Epoch 2/10\n",
      "118123/118123 [==============================] - 1s 4us/step - loss: 0.4535 - acc: 0.8179\n",
      "Epoch 3/10\n",
      "118123/118123 [==============================] - 0s 3us/step - loss: 0.3165 - acc: 0.8992\n",
      "Epoch 4/10\n",
      "118123/118123 [==============================] - 0s 3us/step - loss: 0.2489 - acc: 0.9121\n",
      "Epoch 5/10\n",
      "118123/118123 [==============================] - 0s 3us/step - loss: 0.2223 - acc: 0.9159\n",
      "Epoch 6/10\n",
      "118123/118123 [==============================] - 0s 4us/step - loss: 0.2080 - acc: 0.9246\n",
      "Epoch 7/10\n",
      "118123/118123 [==============================] - 1s 4us/step - loss: 0.1984 - acc: 0.9282\n",
      "Epoch 8/10\n",
      "118123/118123 [==============================] - 0s 4us/step - loss: 0.1914 - acc: 0.9296\n",
      "Epoch 9/10\n",
      "118123/118123 [==============================] - 0s 3us/step - loss: 0.1864 - acc: 0.9313\n",
      "Epoch 10/10\n",
      "118123/118123 [==============================] - 0s 4us/step - loss: 0.1828 - acc: 0.9315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a3d0eb8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3: 29 => 1\n",
    "\n",
    "num_epochs3 = 10  \n",
    "size_batch3 = 1024   \n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(units=16, input_dim=(X_train.shape[1])))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dense(units=8))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dense(units=1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(X_train, y_train, epochs=num_epochs3, batch_size=size_batch3, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
