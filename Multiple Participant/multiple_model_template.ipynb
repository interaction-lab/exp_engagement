{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Indvidualized Participant Engagement Classifcation NN Model\n",
    "\n",
    "# ToDo/Goals: https://docs.google.com/document/d/1_dTnbdRoBV0A7xCxVEyLBdckrlsUnMnRFbbRn39tiXk/edit?usp=sharing\n",
    "# Data: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "#### TODO: Specifiy Data Path Based on Participant/Your Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p3_data_FS4new.csv'\n",
    "p3_data = pd.read_csv(file)\n",
    "p3_data = p3_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p5_data_FS4new.csv'\n",
    "p5_data = pd.read_csv(file)\n",
    "p5_data = p5_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p7_data_FS4new.csv'\n",
    "p7_data = pd.read_csv(file)\n",
    "p7_data = p7_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p8_data_FS4new.csv'\n",
    "p8_data = pd.read_csv(file)\n",
    "p8_data = p8_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p9_data_FS4new.csv'\n",
    "p9_data = pd.read_csv(file)\n",
    "p9_data = p9_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p10_data_FS4new.csv'\n",
    "p10_data = pd.read_csv(file)\n",
    "p10_data = p10_data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulate Train Dataset\n",
    "train = p8_data.copy()\n",
    "train = train.append(p7_data)\n",
    "train = train.append(p5_data)\n",
    "train = train.append(p10_data)\n",
    "train = train.append(p9_data)\n",
    "\n",
    "other = p3_data\n",
    "\n",
    "bogus_test = other['engagement']\n",
    "other_train, other_test, bogus1, bogus2 = train_test_split(other, bogus_test, test_size=0.5, shuffle=False)\n",
    "train = train.append(other_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['engagement']\n",
    "X_train = train.drop(columns=['timestamp', 'session_num', 'engagement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort X,y Train dataframes together after split \n",
    "\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulate Test Dataset\n",
    "\n",
    "test = other_test\n",
    "\n",
    "y_test = test['engagement']\n",
    "X_test = test.drop(columns=['timestamp', 'session_num', 'engagement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "2379816/2379816 [==============================] - 40s 17us/step - loss: 0.4282 - acc: 0.8134\n",
      "Epoch 2/5\n",
      "2379816/2379816 [==============================] - 39s 17us/step - loss: 0.4062 - acc: 0.8286 1 - ETA: 0s - loss: 0.4062 - acc: 0.\n",
      "Epoch 3/5\n",
      "2379816/2379816 [==============================] - 39s 16us/step - loss: 0.4023 - acc: 0.8292 2s - loss: - ETA: 1s \n",
      "Epoch 4/5\n",
      "2379816/2379816 [==============================] - 36s 15us/step - loss: 0.4002 - acc: 0.8295\n",
      "Epoch 5/5\n",
      "2379816/2379816 [==============================] - 38s 16us/step - loss: 0.3990 - acc: 0.8298 1s - loss: 0.3990 - acc - ETA: 1s - loss: 0.3990 - a - ETA: 0s - loss: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x103c8c978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Model: repredict using 10 NN models \n",
    "\n",
    "num_epochs = 5\n",
    "size_batch = 96   \n",
    "\n",
    "nn_model = Sequential()\n",
    "\n",
    "nn_model.add(Dense(units=1, input_dim=(X_train.shape[1])))\n",
    "nn_model.add(Activation('sigmoid'))\n",
    "\n",
    "nn_model.summary()\n",
    "\n",
    "nn_model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nn_model.fit(X_train, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69987/69987 [==============================] - 1s 17us/step\n",
      "[0.4406026242540954, 0.8516010116164431]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = nn_model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nn_model.predict_proba(X_test)\n",
    "pred = nn_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6806414318019061\n",
      "Accuracy: 0.8516010116164431\n",
      "[[ 5415  7172]\n",
      " [ 3214 54186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.43      0.51     12587\n",
      "         1.0       0.88      0.94      0.91     57400\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     69987\n",
      "   macro avg       0.76      0.69      0.71     69987\n",
      "weighted avg       0.84      0.85      0.84     69987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
