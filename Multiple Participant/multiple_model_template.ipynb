{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Indvidualized Participant Engagement Classifcation NN Model\n",
    "\n",
    "# ToDo/Goals: https://docs.google.com/document/d/1_dTnbdRoBV0A7xCxVEyLBdckrlsUnMnRFbbRn39tiXk/edit?usp=sharing\n",
    "# Data: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Specifiy Data Path Based on Participant/Your Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p3_data_FS4.csv'\n",
    "train = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p5_data_FS4.csv'\n",
    "#train2 = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p7_data_FS4.csv'\n",
    "#train3 = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p8_data_FS4.csv'\n",
    "#train4 = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p10_data_FS4.csv'\n",
    "#train5 = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train1.append(train2)\n",
    "#train = train.append(train3)\n",
    "#train = train.append(train4)\n",
    "#train = train.append(train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4/p5_data_FS4.csv'\n",
    "test = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['engagement']\n",
    "X_train = train.drop(columns=['timestamp', 'session_num', 'engagement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort X,y Train dataframes together after split \n",
    "\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['engagement']\n",
    "X_test = test.drop(columns=['timestamp', 'session_num', 'engagement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: May need to adjust following if poor accurracy\n",
    "1. Vary num_epochs, batch size\n",
    "2. Vary between 2, 3, 4 hidden layers\n",
    "3. Vary amount of nodes in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1       # if bad, try 1 - 20\n",
    "size_batch = 64      # if bad, try 16, 32, 64, 128, 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# NN Model for FS4 (all OF/OP)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Dense(units=16, input_dim=(X_train.shape[1]), kernel_initializer='glorot_normal'))\n",
    "model.add(Dense(units=64, input_dim=(X_train.shape[1]), kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(units=16, kernel_initializer='glorot_normal'))\n",
    "model.add(Dense(units=32, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(units=64, kernel_initializer='glorot_normal'))\n",
    "model.add(Dense(units=16, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(units=4, kernel_initializer='glorot_normal'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "139973/139973 [==============================] - 4s 31us/step - loss: 0.1877 - acc: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2dee4d68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use validation split to monitor training, don't use for final recorded accurracy \n",
    "# model.fit(X_train, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1, validation_split=0.1)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339276/339276 [==============================] - 7s 22us/step\n",
      "[0.6938441217815849, 0.8233178886806022]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict_proba(X_test)\n",
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: RECORD ACCURACY IN MODEL RESULTS SPREADSHEET\n",
    "Try to get accurracy, AUC above 90%!!!\n",
    "See results for P8 for guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8467403225523917\n",
      "Accuracy: 0.8233178886806022\n",
      "[[ 54965  51610]\n",
      " [  8334 224367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.52      0.65    106575\n",
      "           1       0.81      0.96      0.88    232701\n",
      "\n",
      "   micro avg       0.82      0.82      0.82    339276\n",
      "   macro avg       0.84      0.74      0.76    339276\n",
      "weighted avg       0.83      0.82      0.81    339276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new = y_test\n",
    "\n",
    "last = -1\n",
    "curr = -1\n",
    "for i,v in enumerate(y_test):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
