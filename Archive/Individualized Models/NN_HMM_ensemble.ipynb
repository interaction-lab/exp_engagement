{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individualized Model: Ensemble -- NN + HMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path: FS4 NEW folder\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/FS4_new/p8_data_FS4new.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split (for chosen Feature Set)\n",
    "\n",
    "#### TODO: Specify which train-test split you want\n",
    "\n",
    "1. Random Shuffle Split: 70-30, 50-50, 30-70, 10-90\n",
    "2. Chronological Split: 70-30, 50-50, 30-70\n",
    "3. Session Split: 70-30, 50-50, 30-70, 10-90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Split: Train on Percentage of Data From Each Session, Sorted Chronologically \n",
    "\n",
    "def session_split(data, size):\n",
    "    sessions = data['session_num'].unique()\n",
    "    \n",
    "    first = True\n",
    "        \n",
    "    for s in sessions:\n",
    "        curr = data.loc[data['session_num'] == s]\n",
    "        curr = curr.sort_values(['timestamp'], ascending=[True])\n",
    "\n",
    "        y = curr['engagement']\n",
    "        X = curr.drop(columns=['timestamp', 'session_num', 'engagement'])\n",
    "\n",
    "        if first:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, shuffle=True)\n",
    "            first = False\n",
    "            \n",
    "        else:\n",
    "            CX_train, CX_test, Cy_train, Cy_test = train_test_split(X, y, test_size=size, shuffle=True)\n",
    "                        \n",
    "            X_train = X_train.append(CX_train)\n",
    "            X_test = X_test.append(CX_test)\n",
    "            y_train = y_train.append(Cy_train)\n",
    "            y_test = y_test.append(Cy_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data (don't need for Random Shuffle, but ok to leave it)\n",
    "\n",
    "data = data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment train-test split to run below \n",
    "\n",
    "y = data['engagement']\n",
    "X = data.drop(columns=['timestamp', 'engagement'])\n",
    "\n",
    "# Choose one of these \n",
    "\n",
    "\n",
    "# 1. Random Shuffle Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "### (Extra)\n",
    "# Random Shuffle Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Random Shuffle Split 30-70\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# Random Shuffle Split 10-90\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "### \n",
    "\n",
    "#############################\n",
    "\n",
    "# 2. Chronological Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# 3. Chronological Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)\n",
    "\n",
    "# 4. Chronological Split 30-70\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, shuffle=False)\n",
    "\n",
    "############################# \n",
    "\n",
    "# 5. Session Split 70-30\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.3)\n",
    "\n",
    "# 6. Session Split 50-50\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.5)\n",
    "\n",
    "# 7. Session Split 30-70\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.7)\n",
    "\n",
    "# 8. Session Split 10-90\n",
    "# X_train, X_test, y_train, y_test = session_split(data, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Session Nums in Order for HMM \n",
    "\n",
    "X_train_sess = X_train['session_num']\n",
    "X_train = X_train.drop(columns=['session_num'])\n",
    "\n",
    "X_test_sess = X_test['session_num']\n",
    "X_test = X_test.drop(columns=['session_num'])\n",
    "\n",
    "X_train_hmm = X_train.copy()\n",
    "y_train_hmm = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort X,y Train dataframes together after split \n",
    "\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)\n",
    "X_train, bogus_test, y_train, bogus_test = train_test_split(X_train, y_train, test_size=0.0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model: Ensemble of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Model (really just a simple classifier): 29 => 1\n",
    "\n",
    "def get_nn_model():\n",
    "    num_epochs = 5\n",
    "    size_batch = 96   \n",
    "\n",
    "    nn_model = Sequential()\n",
    "\n",
    "    nn_model.add(Dense(units=1, input_dim=(X_train.shape[1])))\n",
    "    nn_model.add(Activation('sigmoid'))\n",
    "\n",
    "    nn_model.summary()\n",
    "\n",
    "    nn_model.compile(loss='binary_crossentropy',  \n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    nn_model.fit(X_train, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1)\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = get_nn_model()\n",
    "m2 = get_nn_model()\n",
    "m3 = get_nn_model()\n",
    "m4 = get_nn_model()\n",
    "m5 = get_nn_model()\n",
    "m6 = get_nn_model()\n",
    "m7 = get_nn_model()\n",
    "m8 = get_nn_model()\n",
    "m9 = get_nn_model()\n",
    "m10 = get_nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_pred(nn, X):\n",
    "    nn_pred = nn.predict(X)\n",
    "    nn_pred2 = []\n",
    "    for i in range(0, len(nn_pred)):\n",
    "        nn_pred2.append(nn_pred[i][0])\n",
    "    return nn_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Predictions from 10 NN's to Original Dataframe \n",
    "\n",
    "X_train_nn = X_train.copy()\n",
    "X_train_nn['m1'] = nn_pred(m1, X_train)\n",
    "X_train_nn['m2'] = nn_pred(m2, X_train)\n",
    "X_train_nn['m3'] = nn_pred(m3, X_train)\n",
    "X_train_nn['m4'] = nn_pred(m4, X_train)\n",
    "X_train_nn['m5'] = nn_pred(m5, X_train)\n",
    "X_train_nn['m6'] = nn_pred(m6, X_train)\n",
    "X_train_nn['m7'] = nn_pred(m7, X_train)\n",
    "X_train_nn['m8'] = nn_pred(m8, X_train)\n",
    "X_train_nn['m9'] = nn_pred(m9, X_train)\n",
    "X_train_nn['m10'] = nn_pred(m10, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model: repredict using 10 NN models \n",
    "\n",
    "num_epochs = 5\n",
    "size_batch = 96   \n",
    "\n",
    "nn_model = Sequential()\n",
    "\n",
    "nn_model.add(Dense(units=1, input_dim=(X_train_nn.shape[1])))\n",
    "nn_model.add(Activation('sigmoid'))\n",
    "\n",
    "nn_model.summary()\n",
    "\n",
    "nn_model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nn_model.fit(X_train_nn, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New test data with predictions from 10 NN models\n",
    "\n",
    "X_test_nn = X_test.copy()\n",
    "X_test_nn['m1'] = nn_pred(m1, X_test)\n",
    "X_test_nn['m2'] = nn_pred(m2, X_test)\n",
    "X_test_nn['m3'] = nn_pred(m3, X_test)\n",
    "X_test_nn['m4'] = nn_pred(m4, X_test)\n",
    "X_test_nn['m5'] = nn_pred(m5, X_test)\n",
    "X_test_nn['m6'] = nn_pred(m6, X_test)\n",
    "X_test_nn['m7'] = nn_pred(m7, X_test)\n",
    "X_test_nn['m8'] = nn_pred(m8, X_test)\n",
    "X_test_nn['m9'] = nn_pred(m9, X_test)\n",
    "X_test_nn['m10'] = nn_pred(m10, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = nn_model.evaluate(X_test_nn, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nn_model.predict_proba(X_test_nn)\n",
    "pred = nn_model.predict_classes(X_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM trains on sequences, which is each session. Save Lengths \n",
    "\n",
    "train_lengths = X_train_sess.value_counts(sort=False).tolist()\n",
    "test_lengths = X_test_sess.value_counts(sort=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import random\n",
    "\n",
    "# HMM tends to get stuck in local minimum. For best results, run several times and pick best\n",
    "\n",
    "best_model = GaussianHMM(n_components=2, n_iter=5, algorithm = 'viterbi').fit(X_train_hmm, train_lengths)\n",
    "best_pred = best_model.predict(X_train_hmm, train_lengths)\n",
    "best = accuracy_score(y_train_hmm, best_pred)\n",
    "num = 0\n",
    "\n",
    "for i in range(0,10):\n",
    "    new_model = GaussianHMM(n_components=2, n_iter=5, algorithm = 'viterbi', init_params=\"mcs\")\n",
    "    \n",
    "    # randomly initialize probability matrix \n",
    "    a = random.uniform(0, 1)\n",
    "    b = random.uniform(0, 1)\n",
    "    new_model.transmat_ = np.array([[a, 1-a], [b, 1-b]])\n",
    "\n",
    "    new_model = new_model.fit(X_train_hmm, train_lengths)\n",
    "    \n",
    "    # evaluate this model and see if better than best so far \n",
    "    new_pred = new_model.predict(X_train_hmm, train_lengths)\n",
    "    new_acc = accuracy_score(y_train_hmm, new_pred)\n",
    "    print(i, new_acc)\n",
    "    \n",
    "    if (new_acc > best):\n",
    "        best = new_acc\n",
    "        best_model = new_model\n",
    "        num = i\n",
    "        \n",
    "        \n",
    "hmm_model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HMM Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_pred = hmm_model.predict(X_test, test_lengths)\n",
    "scores = hmm_model.predict_proba(X_test.values, test_lengths)\n",
    "scores = scores[: ,1]\n",
    "\n",
    "print(\"Accuracy for HMM:\",accuracy_score(y_test, hmm_pred))\n",
    "print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "print(metrics.confusion_matrix(y_test, hmm_pred))\n",
    "print(metrics.classification_report(y_test, hmm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model: NN + HMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_pred(nn, X):\n",
    "    nn_pred = nn.predict(X)\n",
    "    nn_pred2 = []\n",
    "    for i in range(0, len(nn_pred)):\n",
    "        nn_pred2.append(nn_pred[i][0])\n",
    "    return nn_pred2\n",
    "\n",
    "def hmm_pred(X, lengths):\n",
    "    scores = hmm_model.predict_proba(X.values, lengths)\n",
    "    scores = scores[: ,1]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep X_train_hmm for X_train_ens:\n",
    "X_train_ens_nn = X_train_hmm.copy()\n",
    "X_train_ens_nn['m1'] = nn_pred(m1, X_train_hmm)\n",
    "X_train_ens_nn['m2'] = nn_pred(m2, X_train_hmm)\n",
    "X_train_ens_nn['m3'] = nn_pred(m3, X_train_hmm)\n",
    "X_train_ens_nn['m4'] = nn_pred(m4, X_train_hmm)\n",
    "X_train_ens_nn['m5'] = nn_pred(m5, X_train_hmm)\n",
    "X_train_ens_nn['m6'] = nn_pred(m6, X_train_hmm)\n",
    "X_train_ens_nn['m7'] = nn_pred(m7, X_train_hmm)\n",
    "X_train_ens_nn['m8'] = nn_pred(m8, X_train_hmm)\n",
    "X_train_ens_nn['m9'] = nn_pred(m9, X_train_hmm)\n",
    "X_train_ens_nn['m10'] = nn_pred(m10, X_train_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE Data\n",
    "\n",
    "X_train_ens = X_train_hmm.copy()\n",
    "X_train_ens['nn_model'] = nn_pred(nn_model, X_train_ens_nn)\n",
    "X_train_ens['hmm_model'] = hmm_pred(X_train_hmm, train_lengths)\n",
    "\n",
    "y_train_ens = y_train_hmm.copy()\n",
    "\n",
    "X_test_ens = X_test.copy()\n",
    "X_test_ens['nn_model'] = nn_pred(nn_model, X_test_nn)\n",
    "X_test_ens['hmm_model'] = hmm_pred(X_test, test_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle Train Dataset\n",
    "\n",
    "X_train_ens, bogus_test, y_train_ens, bogus_test = train_test_split(X_train_ens, y_train_ens, test_size=0.0, shuffle=True)\n",
    "X_train_ens, bogus_test, y_train_ens, bogus_test = train_test_split(X_train_ens, y_train_ens, test_size=0.0, shuffle=True)\n",
    "X_train_ens, bogus_test, y_train_ens, bogus_test = train_test_split(X_train_ens, y_train_ens, test_size=0.0, shuffle=True)\n",
    "X_train_ens, bogus_test, y_train_ens, bogus_test = train_test_split(X_train_ens, y_train_ens, test_size=0.0, shuffle=True)\n",
    "X_train_ens, bogus_test, y_train_ens, bogus_test = train_test_split(X_train_ens, y_train_ens, test_size=0.0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model (really just a simple classifier): 29 => 1\n",
    "\n",
    "num_epochs = 5\n",
    "size_batch = 96   \n",
    "\n",
    "ens_model = Sequential()\n",
    "\n",
    "ens_model.add(Dense(units=1, input_dim=(X_train_ens.shape[1])))\n",
    "ens_model.add(Activation('sigmoid'))\n",
    "\n",
    "ens_model.summary()\n",
    "\n",
    "ens_model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ens_model.fit(X_train_ens, y_train_ens, epochs=num_epochs, batch_size=size_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Ensemble Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = ens_model.evaluate(X_test_ens, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_scores = ens_model.predict_proba(X_test_ens)\n",
    "ens_pred = ens_model.predict_classes(X_test_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, ens_scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, ens_pred))\n",
    "print(metrics.confusion_matrix(y_test, ens_pred))\n",
    "print(metrics.classification_report(y_test, ens_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_test_ens['nn_model']\n",
    "b = X_test_ens['hmm_model']\n",
    "c = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_c = 0\n",
    "m2_c = 0\n",
    "b_c = 0\n",
    "n_c = 0\n",
    "\n",
    "for i in range(77980, 181956):\n",
    "    if (a[i] == c[i]) and (b[i] == c[i]):\n",
    "        b_c += 1\n",
    "    elif (a[i] == c[i]):\n",
    "        m1_c += 1\n",
    "    elif (b[i] == c[i]):\n",
    "        m2_c += 1\n",
    "    else:\n",
    "        n_c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m1_c, m2_c, b_c, n_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m1_c+b_c)/(n_c+b_c+m1_c+m2_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
