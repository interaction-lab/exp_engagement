{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, Split, Train set, Test set, Include x% of test participant in train, Feature Set, Preprocessing, Algorithm\n",
    "# String, Float (0-1), List, List, Float (0-1), String, String, String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset, split, train, test, includex, features, preprocessing):\n",
    "    \n",
    "    if(split>0):\n",
    "        if(dataset=='regular'):\n",
    "            path = 'data/Master/' + item + '_master.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:]\n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "        elif(dataset=='smooth'):\n",
    "            path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:]\n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "        else:\n",
    "            path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:] \n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "    else:\n",
    "        # Training Data\n",
    "        train_df = pd.DataFrame()\n",
    "        for item in train:\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)       \n",
    "\n",
    "        # Include x% of Test Participants Data\n",
    "        if(includex>0):\n",
    "            item = test[0]\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)      \n",
    "\n",
    "        # Test Data\n",
    "        test_df = pd.DataFrame()\n",
    "        for item in test:\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)   \n",
    "    \n",
    "    y_train = train_df['engagement']\n",
    "    y_test = test_df['engagement']\n",
    "    X_train = train_df.drop(['engagement'],axis = 1)\n",
    "    X_test = test_df.drop(['engagement'],axis = 1)\n",
    "    \n",
    "    \n",
    "    if(features == 'variance_threshold'):\n",
    "        selector = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "        selector.fit(X_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        \n",
    "    if(preprocessing == 'standard'):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    elif(preprocessing == 'minmax'):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    imputer.fit(X_train)\n",
    "    X_train = imputer.transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_test, y_train, y_test, algorithm):\n",
    "    if(algorithm == 'logistic'):\n",
    "        clf = LogisticRegression(solver='lbfgs') \n",
    "    elif(algorithm == 'naivebayes'):\n",
    "        clf = GaussianNB(var_smoothing=1e-8)\n",
    "    else:\n",
    "        clf = LinearSVC()\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    try:\n",
    "        scores = clf.decision_function(X_test)\n",
    "    except:\n",
    "        scores = clf.predict_proba(X_test)\n",
    "        sd = pd.DataFrame(scores)\n",
    "        scores = sd[1]\n",
    "    #print scores\n",
    "    # Accuracy:\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test,pred))\n",
    "    print(metrics.classification_report(y_test,pred))\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "    try:\n",
    "        print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "    except:\n",
    "        print(\"AUC undefinied, only 1 class in test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p5,p7]\n",
    "\n",
    "- test = [p9]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.7103273596698564)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.51      0.65    191811\n",
      "           1       0.63      0.93      0.75    174575\n",
      "\n",
      "   micro avg       0.71      0.71      0.71    366386\n",
      "   macro avg       0.76      0.72      0.70    366386\n",
      "weighted avg       0.77      0.71      0.70    366386\n",
      "\n",
      "[[ 97405  94406]\n",
      " [ 11726 162849]]\n",
      "('AUC:', 0.8066723789463343)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.7252460519779685)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.56      0.68    191811\n",
      "           1       0.65      0.91      0.76    174575\n",
      "\n",
      "   micro avg       0.73      0.73      0.73    366386\n",
      "   macro avg       0.76      0.73      0.72    366386\n",
      "weighted avg       0.77      0.73      0.72    366386\n",
      "\n",
      "[[107098  84713]\n",
      " [ 15953 158622]]\n",
      "('AUC:', 0.8359379959215113)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.7133351165164608)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.51      0.65    191811\n",
      "           1       0.64      0.93      0.76    174575\n",
      "\n",
      "   micro avg       0.71      0.71      0.71    366386\n",
      "   macro avg       0.76      0.72      0.70    366386\n",
      "weighted avg       0.77      0.71      0.70    366386\n",
      "\n",
      "[[ 98692  93119]\n",
      " [ 11911 162664]]\n",
      "('AUC:', 0.8307942366828736)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.7264196776077688)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.55      0.68    191811\n",
      "           1       0.65      0.91      0.76    174575\n",
      "\n",
      "   micro avg       0.73      0.73      0.73    366386\n",
      "   macro avg       0.76      0.73      0.72    366386\n",
      "weighted avg       0.77      0.73      0.72    366386\n",
      "\n",
      "[[106415  85396]\n",
      " [ 14840 159735]]\n",
      "('AUC:', 0.8409249011083906)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.7428641631516442)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.61      0.71     12792\n",
      "         1.0       0.67      0.89      0.77     11627\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     24419\n",
      "   macro avg       0.77      0.75      0.74     24419\n",
      "weighted avg       0.77      0.74      0.74     24419\n",
      "\n",
      "[[ 7774  5018]\n",
      " [ 1261 10366]]\n",
      "('AUC:', 0.8294257228799305)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.4786027273844138)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.01      0.02     12792\n",
      "         1.0       0.48      0.99      0.64     11627\n",
      "\n",
      "   micro avg       0.48      0.48      0.48     24419\n",
      "   macro avg       0.55      0.50      0.33     24419\n",
      "weighted avg       0.55      0.48      0.32     24419\n",
      "\n",
      "[[  156 12636]\n",
      " [   96 11531]]\n",
      "('AUC:', 0.635715886573987)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.7568286989639216)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.62      0.73     12792\n",
      "         1.0       0.68      0.91      0.78     11627\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     24419\n",
      "   macro avg       0.78      0.76      0.75     24419\n",
      "weighted avg       0.79      0.76      0.75     24419\n",
      "\n",
      "[[ 7894  4898]\n",
      " [ 1040 10587]]\n",
      "('AUC:', 0.8398044472891024)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.4797084237683771)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.02      0.03     12792\n",
      "         1.0       0.48      0.99      0.64     11627\n",
      "\n",
      "   micro avg       0.48      0.48      0.48     24419\n",
      "   macro avg       0.56      0.50      0.34     24419\n",
      "weighted avg       0.56      0.48      0.32     24419\n",
      "\n",
      "[[  202 12590]\n",
      " [  115 11512]]\n",
      "('AUC:', 0.6402623415727116)\n",
      "\n",
      "\n",
      "CPU times: user 43 s, sys: 10 s, total: 53 s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p5','p7'],['p9'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'naivebayes')\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p7,p9]\n",
    "\n",
    "- test = [p5]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.8660653914924947)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.68      0.79     95873\n",
      "           1       0.84      0.97      0.90    170339\n",
      "\n",
      "   micro avg       0.87      0.87      0.87    266212\n",
      "   macro avg       0.89      0.83      0.84    266212\n",
      "weighted avg       0.87      0.87      0.86    266212\n",
      "\n",
      "[[ 65189  30684]\n",
      " [  4971 165368]]\n",
      "('AUC:', 0.8831595974534097)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.8595330037714303)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.65      0.77     95873\n",
      "           1       0.83      0.98      0.90    170339\n",
      "\n",
      "   micro avg       0.86      0.86      0.86    266212\n",
      "   macro avg       0.89      0.81      0.83    266212\n",
      "weighted avg       0.87      0.86      0.85    266212\n",
      "\n",
      "[[ 62242  33631]\n",
      " [  3763 166576]]\n",
      "('AUC:', 0.913991653860679)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.8652727901071326)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.78     95873\n",
      "           1       0.84      0.97      0.90    170339\n",
      "\n",
      "   micro avg       0.87      0.87      0.87    266212\n",
      "   macro avg       0.89      0.82      0.84    266212\n",
      "weighted avg       0.88      0.87      0.86    266212\n",
      "\n",
      "[[ 64381  31492]\n",
      " [  4374 165965]]\n",
      "('AUC:', 0.8841086414198056)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.8598673237870569)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.65      0.77     95873\n",
      "           1       0.83      0.98      0.90    170339\n",
      "\n",
      "   micro avg       0.86      0.86      0.86    266212\n",
      "   macro avg       0.89      0.81      0.83    266212\n",
      "weighted avg       0.87      0.86      0.85    266212\n",
      "\n",
      "[[ 62339  33534]\n",
      " [  3771 166568]]\n",
      "('AUC:', 0.9133404211441138)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n",
      "('Accuracy:', 0.8016235413495687)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.66      0.71      6400\n",
      "         1.0       0.82      0.88      0.85     11339\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     17739\n",
      "   macro avg       0.79      0.77      0.78     17739\n",
      "weighted avg       0.80      0.80      0.80     17739\n",
      "\n",
      "[[4251 2149]\n",
      " [1370 9969]]\n",
      "('AUC:', 0.8028903976320664)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.6389311686115339)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.00      0.00      6400\n",
      "         1.0       0.64      1.00      0.78     11339\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     17739\n",
      "   macro avg       0.47      0.50      0.39     17739\n",
      "weighted avg       0.52      0.64      0.50     17739\n",
      "\n",
      "[[    4  6396]\n",
      " [    9 11330]]\n",
      "('AUC:', 0.6711349793853073)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.8150403066689216)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.64      0.71      6400\n",
      "         1.0       0.82      0.92      0.86     11339\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     17739\n",
      "   macro avg       0.81      0.78      0.79     17739\n",
      "weighted avg       0.81      0.82      0.81     17739\n",
      "\n",
      "[[ 4069  2331]\n",
      " [  950 10389]]\n",
      "('AUC:', 0.8014494843570861)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.6390439145385873)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.00      0.00      6400\n",
      "         1.0       0.64      1.00      0.78     11339\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     17739\n",
      "   macro avg       0.52      0.50      0.39     17739\n",
      "weighted avg       0.55      0.64      0.50     17739\n",
      "\n",
      "[[    6  6394]\n",
      " [    9 11330]]\n",
      "('AUC:', 0.671856872574742)\n",
      "\n",
      "\n",
      "CPU times: user 41.5 s, sys: 10 s, total: 51.5 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p7','p9'],['p5'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'naivebayes')\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p5,p9]\n",
    "\n",
    "- test = [p7]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.807582089203796)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78    173189\n",
      "           1       0.74      0.93      0.83    169487\n",
      "\n",
      "   micro avg       0.81      0.81      0.81    342676\n",
      "   macro avg       0.83      0.81      0.80    342676\n",
      "weighted avg       0.83      0.81      0.80    342676\n",
      "\n",
      "[[118291  54898]\n",
      " [ 11039 158448]]\n",
      "('AUC:', 0.8844101870669858)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.7899269280603252)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.65      0.76    173189\n",
      "           1       0.72      0.94      0.82    169487\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    342676\n",
      "   macro avg       0.82      0.79      0.79    342676\n",
      "weighted avg       0.82      0.79      0.79    342676\n",
      "\n",
      "[[111727  61462]\n",
      " [ 10525 158962]]\n",
      "('AUC:', 0.8898446460960444)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.8011386849385426)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77    173189\n",
      "           1       0.73      0.94      0.82    169487\n",
      "\n",
      "   micro avg       0.80      0.80      0.80    342676\n",
      "   macro avg       0.83      0.80      0.80    342676\n",
      "weighted avg       0.83      0.80      0.80    342676\n",
      "\n",
      "[[115091  58098]\n",
      " [ 10047 159440]]\n",
      "('AUC:', 0.8781703439124112)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.7857538899718685)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75    173189\n",
      "           1       0.72      0.94      0.81    169487\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    342676\n",
      "   macro avg       0.82      0.79      0.78    342676\n",
      "weighted avg       0.82      0.79      0.78    342676\n",
      "\n",
      "[[110156  63033]\n",
      " [ 10384 159103]]\n",
      "('AUC:', 0.890100209749127)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n",
      "('Accuracy:', 0.8231584479285277)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83     11549\n",
      "         1.0       0.82      0.82      0.82     11285\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     22834\n",
      "   macro avg       0.82      0.82      0.82     22834\n",
      "weighted avg       0.82      0.82      0.82     22834\n",
      "\n",
      "[[9533 2016]\n",
      " [2022 9263]]\n",
      "('AUC:', 0.8840782698043776)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.49435052991153544)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.00      0.00     11549\n",
      "         1.0       0.49      1.00      0.66     11285\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     22834\n",
      "   macro avg       0.52      0.50      0.33     22834\n",
      "weighted avg       0.52      0.49      0.33     22834\n",
      "\n",
      "[[   19 11530]\n",
      " [   16 11269]]\n",
      "('AUC:', 0.6314534556444651)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.825654725409477)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.77      0.82     11549\n",
      "         1.0       0.79      0.88      0.83     11285\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     22834\n",
      "   macro avg       0.83      0.83      0.83     22834\n",
      "weighted avg       0.83      0.83      0.83     22834\n",
      "\n",
      "[[8941 2608]\n",
      " [1373 9912]]\n",
      "('AUC:', 0.8874238037898508)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.4943943242533065)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.00      0.00     11549\n",
      "         1.0       0.49      1.00      0.66     11285\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     22834\n",
      "   macro avg       0.52      0.50      0.33     22834\n",
      "weighted avg       0.53      0.49      0.33     22834\n",
      "\n",
      "[[   20 11529]\n",
      " [   16 11269]]\n",
      "('AUC:', 0.6320036915390427)\n",
      "\n",
      "\n",
      "CPU times: user 43.3 s, sys: 10.1 s, total: 53.4 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p5','p9'],['p7'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'naivebayes')\n",
    "                print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
