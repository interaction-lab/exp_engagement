{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Indvidualized Participant Engagement Classifcation NN Model\n",
    "\n",
    "# ToDo/Goals: https://docs.google.com/document/d/1_dTnbdRoBV0A7xCxVEyLBdckrlsUnMnRFbbRn39tiXk/edit?usp=sharing\n",
    "# Data: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Specifiy Data Path Based on Participant/Your Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Specify Data Path based on participant/your computer\n",
    "# Warning: this will probably take some time\n",
    "\n",
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/p8_data_processed.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>session_num</th>\n",
       "      <th>session_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>engagement</th>\n",
       "      <th>activity</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>aptitude</th>\n",
       "      <th>games_total</th>\n",
       "      <th>...</th>\n",
       "      <th>op_p2_pose_y9</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  session_num session_date  timestamp  engagement  activity  \\\n",
       "0          8.0          1.0   2018-06-07   0.000000         1.0       NaN   \n",
       "1          8.0          1.0   2018-06-07   0.033333         1.0       NaN   \n",
       "2          8.0          1.0   2018-06-07   0.066667         1.0       NaN   \n",
       "3          8.0          1.0   2018-06-07   0.100000         1.0       NaN   \n",
       "4          8.0          1.0   2018-06-07   0.133333         1.0       NaN   \n",
       "\n",
       "  skill  difficulty  aptitude  games_total   ...     op_p2_pose_y9  skill_NC  \\\n",
       "0   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "1   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "2   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "3   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "4   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "\n",
       "   skill_OS  skill_EM  diff_1  diff_2  diff_3  diff_4  diff_5  no_game  \n",
       "0         0         0       0       0       0       0       0        1  \n",
       "1         0         0       0       0       0       0       0        1  \n",
       "2         0         0       0       0       0       0       0        1  \n",
       "3         0         0       0       0       0       0       0        1  \n",
       "4         0         0       0       0       0       0       0        1  \n",
       "\n",
       "[5 rows x 1572 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "\n",
    "# transcriptions\n",
    "data = data.drop(columns=['transcript_spk_0', 'transcript_spk_1', 'transcript_spk_2'])\n",
    "\n",
    "# raw ros messages\n",
    "data = data.drop(columns=['ros_PARTICIPANT_STATE', 'ros_ROBOT_STATE'])\n",
    "\n",
    "# more for counting purposes\n",
    "data = data.drop(columns=['game_start', 'game_correct', 'game_incorrect', 'mistake_made'])\n",
    "\n",
    "data = data.drop(columns=['participant', 'session_date'])\n",
    "\n",
    "# use one-hot encoded difficulty and skill, don't use activity for now\n",
    "data = data.drop(columns=['difficulty', 'skill', 'activity', 'of_face_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Face/Open-Pose Columns? \n",
    "# Feature Dictionary Documentation here: https://docs.google.com/document/d/1RSygoLwsM1PKEIOoqDOaEo3lRBZBLZJuzbMSY5K_6zA/edit?usp=sharing\n",
    "\n",
    "only_ofop = []\n",
    "performance = []\n",
    "for i in data.columns:\n",
    "    # open face/open pose columns begin with of_ or op_\n",
    "    if 'op_' in i or 'of_' in i:\n",
    "        only_ofop.append(i)\n",
    "    else:\n",
    "        performance.append(i)\n",
    "        \n",
    "only_ofop.remove('of_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    139463\n",
      "0.0    120473\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.5365282223316509\n",
      "0 0.4634717776683491\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Feature Set\n",
    "#### (FS4: Performance + Handpicked OF/OP from Caitlyn's Intuition)\n",
    "Note: keep timestamp and session_num until right before running the model in all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 4: Performance + Handpicked OF/OP\n",
    "\n",
    "hand_picked = ['confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'gaze_angle_x', 'gaze_angle_y']\n",
    "for i,c in enumerate(hand_picked):\n",
    "    hand_picked[i] = 'of_' + c\n",
    "hand_picked.append('op_Number of People')\n",
    "\n",
    "for i in performance:\n",
    "    hand_picked.append(i)\n",
    "\n",
    "FS = data[hand_picked]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Test Split (for chosen Feature Set)\n",
    "\n",
    "#### TODO: Specify which train-test split you want\n",
    "\n",
    "1. Random Shuffle Split: 70-30, 50-50, 30-70\n",
    "2. Chronological Split (80-20, 70-30, 60-40, 50-50, 40-60, 30-70, 20-80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data (don't need for Random Shuffle, but ok to leave it)\n",
    "\n",
    "data = data.sort_values(['session_num', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment correct train-test split below\n",
    "\n",
    "y = FS['engagement']\n",
    "X = FS.drop(columns=['timestamp', 'session_num', 'engagement'])\n",
    "\n",
    "# Choose one of these \n",
    "\n",
    "# 1. Random Shuffle Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 2. Random Shuffle Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# 3. Random Shuffle Split 30-70\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "#############################\n",
    "\n",
    "# 4. Chronological Split 80-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# 5. Random Shuffle Split 70-30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# 6. Random Shuffle Split 60-40\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "\n",
    "# 7. Random Shuffle Split 50-50\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)\n",
    "\n",
    "# 8. Random Shuffle Split 40-60\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, shuffle=False)\n",
    "\n",
    "# 9. Random Shuffle Split 30-70\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, shuffle=False)\n",
    "\n",
    "# 10. Random Shuffle Split 20-80\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: May need to adjust following if poor accurracy\n",
    "1. Vary num_epochs, batch size\n",
    "2. Vary between 2, 3, 4 hidden layers\n",
    "3. Vary amount of nodes in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10          # if bad, try 5, 10, 15, 20 \n",
    "size_batch = 128         # if bad, try 64, 128, 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,033\n",
      "Trainable params: 4,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# NN Model for FS4 (all OF/OP)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, input_dim=len(X_train.columns)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',  \n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "207948/207948 [==============================] - 4s 17us/step - loss: 0.3701 - acc: 0.8321\n",
      "Epoch 2/10\n",
      "207948/207948 [==============================] - 3s 14us/step - loss: 0.2788 - acc: 0.8815\n",
      "Epoch 3/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.2438 - acc: 0.8970\n",
      "Epoch 4/10\n",
      "207948/207948 [==============================] - 3s 14us/step - loss: 0.2235 - acc: 0.9042\n",
      "Epoch 5/10\n",
      "207948/207948 [==============================] - 3s 14us/step - loss: 0.2092 - acc: 0.9111\n",
      "Epoch 6/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.1969 - acc: 0.9169\n",
      "Epoch 7/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.1883 - acc: 0.9209\n",
      "Epoch 8/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.1800 - acc: 0.9249\n",
      "Epoch 9/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.1741 - acc: 0.9286\n",
      "Epoch 10/10\n",
      "207948/207948 [==============================] - 3s 15us/step - loss: 0.1672 - acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30102908>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=size_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51988/51988 [==============================] - 1s 22us/step\n",
      "[1.0341490454856355, 0.7591559590674771]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict_proba(X_test)\n",
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: RECORD ACCURACY IN MODEL RESULTS SPREADSHEET\n",
    "Try to get accurracy, AUC above 90%!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC undefinied, only 1 class in test data\n",
      "Accuracy: 0.7591559590674771\n",
      "[[39467 12521]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.76      0.86     51988\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     51988\n",
      "   macro avg       0.50      0.38      0.43     51988\n",
      "weighted avg       1.00      0.76      0.86     51988\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "except:\n",
    "    print(\"AUC undefinied, only 1 class in test data\")\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(y_test, pred))\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
