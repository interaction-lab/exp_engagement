{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Engagement Classifcation Model\n",
    "\n",
    "# ToDo/Models to run here: https://docs.google.com/document/d/18EJpFesMEl9Q7C1AZzDeq6uy7c8tDMvEJ_j58-MmiBI/edit?usp=sharing\n",
    "# Use p8_data_processed.csv here: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Warning: this will probably take some time\n",
    "# Adjust file path based on your computer\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/p8_data_processed.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>session_num</th>\n",
       "      <th>session_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>engagement</th>\n",
       "      <th>activity</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>aptitude</th>\n",
       "      <th>games_total</th>\n",
       "      <th>...</th>\n",
       "      <th>op_p2_pose_y9</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  session_num session_date  timestamp  engagement  activity  \\\n",
       "0          8.0          1.0   2018-06-07   0.000000         1.0       NaN   \n",
       "1          8.0          1.0   2018-06-07   0.033333         1.0       NaN   \n",
       "2          8.0          1.0   2018-06-07   0.066667         1.0       NaN   \n",
       "3          8.0          1.0   2018-06-07   0.100000         1.0       NaN   \n",
       "4          8.0          1.0   2018-06-07   0.133333         1.0       NaN   \n",
       "\n",
       "  skill  difficulty  aptitude  games_total   ...     op_p2_pose_y9  skill_NC  \\\n",
       "0   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "1   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "2   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "3   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "4   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "\n",
       "   skill_OS  skill_EM  diff_1  diff_2  diff_3  diff_4  diff_5  no_game  \n",
       "0         0         0       0       0       0       0       0        1  \n",
       "1         0         0       0       0       0       0       0        1  \n",
       "2         0         0       0       0       0       0       0        1  \n",
       "3         0         0       0       0       0       0       0        1  \n",
       "4         0         0       0       0       0       0       0        1  \n",
       "\n",
       "[5 rows x 1572 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "\n",
    "# transcriptions\n",
    "data = data.drop(columns=['transcript_spk_0', 'transcript_spk_1', 'transcript_spk_2'])\n",
    "\n",
    "# raw ros messages\n",
    "data = data.drop(columns=['ros_PARTICIPANT_STATE', 'ros_ROBOT_STATE'])\n",
    "\n",
    "# more for counting purposes\n",
    "data = data.drop(columns=['game_start', 'game_correct', 'game_incorrect', 'mistake_made'])\n",
    "\n",
    "data = data.drop(columns=['participant', 'session_date'])\n",
    "\n",
    "# use one-hot encoded difficulty and skill, don't use activity for now\n",
    "data = data.drop(columns=['difficulty', 'skill', 'activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_num\n",
      "timestamp\n",
      "engagement\n",
      "aptitude\n",
      "games_total\n",
      "games_session\n",
      "mistakes_total\n",
      "mistakes_session\n",
      "mistakes_game\n",
      "ts_robot_talked\n",
      "ts_game_start\n",
      "ts_attempt\n",
      "skill_NC\n",
      "skill_OS\n",
      "skill_EM\n",
      "diff_1\n",
      "diff_2\n",
      "diff_3\n",
      "diff_4\n",
      "diff_5\n",
      "no_game\n"
     ]
    }
   ],
   "source": [
    "# What Non Open-Face/Open-Pose Columns? \n",
    "# Feature Dictionary Documentation here: https://docs.google.com/document/d/1RSygoLwsM1PKEIOoqDOaEo3lRBZBLZJuzbMSY5K_6zA/edit?usp=sharing\n",
    "\n",
    "only_ofop = []\n",
    "for i in data.columns:\n",
    "    # open face/open pose columns begin with of_ or op_\n",
    "    if 'op_' not in i and 'of_' not in i:\n",
    "        print(i)\n",
    "    else:\n",
    "        only_ofop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    139463\n",
      "0.0    120473\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.5365282223316509\n",
      "0 0.4634717776683491\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision 1: What features to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Drop Some OpenFace/OpenPose Columns \n",
    "\n",
    "# Run a model with ONLY open face/ open pose columns\n",
    "#only_ofop.append('timestamp')\n",
    "#only_ofop.append('session_num')\n",
    "#only_ofop.append('engagement')\n",
    "#data = data[only_ofop]\n",
    "\n",
    "# Run a model with only critical open face/open pose columns as determined by Bala's feature analysis\n",
    "\n",
    "hand_picked = ['confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'gaze_angle_x', 'gaze_angle_y']\n",
    "for i,c in enumerate(hand_picked):\n",
    "    hand_picked[i] = 'of_' + c\n",
    "hand_picked.append('op_Number of People')\n",
    "\n",
    "hand_picked.append('timestamp')\n",
    "hand_picked.append('session_num')\n",
    "hand_picked.append('engagement')\n",
    "data = data[hand_picked]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision 2: Train Test Split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Sort Data Chronologically\n",
    "# Important for Sequential Models! \n",
    "\n",
    "# data = data.sort_values(['session_num', 'timestamp'], ascending=[True, True])\n",
    "\n",
    "# shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure engagement is first column\n",
    "\n",
    "cols = list(data)\n",
    "cols.insert(0, cols.pop(cols.index('engagement')))\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split 2: Train on Earlier Sessions, Test on Later Sessions\n",
    "\n",
    "session_threshold = 8 # train on sessions <= 8, test on sessions > 8\n",
    "\n",
    "train = data[(data['session_num'] <= 8.0)] \n",
    "test = data[(data['session_num'] > 8)]\n",
    "\n",
    "# drop columns needed for split\n",
    "train = train.drop(columns=['session_num', 'timestamp'])\n",
    "test = test.drop(columns=['session_num', 'timestamp'])\n",
    "\n",
    "X_train2 = train.iloc[:,1:]\n",
    "y_train2 = train.iloc[:, 0]\n",
    "\n",
    "X_test2 = test.iloc[:, 1:]\n",
    "y_test2 = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split 1: Random 70-30 Split\n",
    "\n",
    "# don't need these columns anymore\n",
    "data = data.drop(columns=['session_num', 'timestamp'])\n",
    "\n",
    "# Note: random_state: make sure we get same split every time \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data.iloc[:,1:], data.iloc[:,0], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision0(y_true, y_pred):\n",
    "    data_tuples = list(zip(y_true, y_pred))\n",
    "    df = pd.DataFrame(data_tuples, columns=['true', 'pred'])\n",
    "    df = df.round(0)\n",
    "    \n",
    "    true_pos = len(df[(df['true'] <= 0) & (df['pred'] <= 0)])\n",
    "    pred_pos = len(df[(df['pred'] <= 0)])\n",
    "    return float(true_pos) / float(pred_pos)\n",
    "\n",
    "def recall0(y_true, y_pred):\n",
    "    data_tuples = list(zip(y_true, y_pred))\n",
    "    df = pd.DataFrame(data_tuples, columns=['true', 'pred'])\n",
    "    df = df.round(0)\n",
    "\n",
    "    true_pos = len(df[(df['true'] <= 0) & (df['pred'] <= 0)])\n",
    "    real_pos = len(df[(df['true'] <= 0)])\n",
    "    return float(true_pos) / float(real_pos)\n",
    "\n",
    "def f1_0(y_true, y_pred):\n",
    "    p = precision0(y_true, y_pred)\n",
    "    r = precision0(y_true, y_pred)\n",
    "\n",
    "    return (2*((p*r)/(p+r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision1(y_true, y_pred):\n",
    "    data_tuples = list(zip(y_true, y_pred))\n",
    "    df = pd.DataFrame(data_tuples, columns=['true', 'pred'])\n",
    "    df = df.round(0)\n",
    "\n",
    "    true_pos = len(df[(df['true'] >= 1) & (df['pred'] >= 1)])\n",
    "    pred_pos = len(df[(df['pred'] >= 1)])\n",
    "    return float(true_pos) / float(pred_pos)\n",
    "\n",
    "def recall1(y_true, y_pred):\n",
    "    data_tuples = list(zip(y_true, y_pred))\n",
    "    df = pd.DataFrame(data_tuples, columns=['true', 'pred'])\n",
    "    df = df.round(0)\n",
    "\n",
    "    true_pos = len(df[(df['true'] >= 1) & (df['pred'] >= 1)])\n",
    "    real_pos = len(df[(df['true'] >= 1)])\n",
    "    return float(true_pos) / float(real_pos)\n",
    "\n",
    "def f1_1(y_true, y_pred):\n",
    "    p = precision1(y_true, y_pred)\n",
    "    r = precision1(y_true, y_pred)\n",
    "    \n",
    "    return (2*((p*r)/(p+r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    print(y_true)\n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: NN, Random 70-30 Split, hand_picked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train1.values\n",
    "X_test1 = X_test1.values\n",
    "y_train1 = y_train1.values\n",
    "y_test1 = y_test1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181955, 11)\n",
      "(77981, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1.shape)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,609\n",
      "Trainable params: 4,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize simple neural network model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=32, input_dim=11)) # Dense = fully-connected\n",
    "model.add(Activation('relu')) # Relu activation (avoid unstable gradient problem)\n",
    "\n",
    "model.add(Dense(units=64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', # specify crossentropy cost function \n",
    "              optimizer='sgd', # stochastic gradient descent\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2776ff60>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1, epochs=20, batch_size=64, verbose=0, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77981/77981 [==============================] - 0s 5us/step\n",
      "[0.4818522943521359, 0.7579795078250083]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test1, y_test1, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, nb_classes):\n",
    "    y = np.asarray(y, dtype='int32')\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    Y[np.arange(len(y)),y] = 1.\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(y_train1, 2)\n",
    "y_test1 = to_categorical(y_test1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Logistic Regression Model using TensorFlow\n",
    "import tensorflow as tf\n",
    "# Set up the TensorFlow variables (Add variables to TensorFlow's computational graph)\n",
    "\n",
    "# this just helps with using tensorflow inside jupyter (reset/clear all tf variables)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input Parameter\n",
    "x = tf.placeholder(tf.float32, [None, 11])\n",
    "\n",
    "# Weights Variable (xavier initializer -- random values centered around zero)\n",
    "W = tf.get_variable(\"W\", shape=[11, 2], initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# Biases variable: initialized to zero\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# Define hypothesis fxn (y): represents probability of possible outputs given inputs\n",
    "# Uses the softmax activation function: like sigmoid, but makes sure probabiltiies add to 1    \n",
    "y = tf.nn.sigmoid(tf.matmul(x, W)+b)\n",
    "\n",
    "# y_: actual labels\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size):\n",
    "    indexes = np.random.randint(len(X_train1), size = (batch_size,))\n",
    "    return X_train1[indexes], y_train1[indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/tensorflow/python/client/session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(.01).minimize(loss) # \".01\" specifies the learning rate\n",
    "sess = tf.InteractiveSession() # create the sesion object\n",
    "tf.global_variables_initializer().run() # initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    # get the x training batch and y training batch\n",
    "    batch_xs, batch_ys = generate_batch(500)\n",
    "    \n",
    "    # this evaluates the computational graph\n",
    "    # passes batch_xs in for the x placeholder, batch_ys in for the y_ placeholder\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65709597\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: X_test1, y_: y_test1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
