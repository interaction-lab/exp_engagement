{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Engagement Classifcation Model\n",
    "\n",
    "# ToDo/Models to run here: https://docs.google.com/document/d/18EJpFesMEl9Q7C1AZzDeq6uy7c8tDMvEJ_j58-MmiBI/edit?usp=sharing\n",
    "# Use p8_data_processed.csv here: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Warning: this will probably take some time\n",
    "# Adjust file path based on your computer\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/p8_data_processed.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>session_num</th>\n",
       "      <th>session_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>engagement</th>\n",
       "      <th>activity</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>aptitude</th>\n",
       "      <th>games_total</th>\n",
       "      <th>...</th>\n",
       "      <th>op_p2_pose_y9</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  session_num session_date  timestamp  engagement  activity  \\\n",
       "0          8.0          1.0   2018-06-07   0.000000         1.0       NaN   \n",
       "1          8.0          1.0   2018-06-07   0.033333         1.0       NaN   \n",
       "2          8.0          1.0   2018-06-07   0.066667         1.0       NaN   \n",
       "3          8.0          1.0   2018-06-07   0.100000         1.0       NaN   \n",
       "4          8.0          1.0   2018-06-07   0.133333         1.0       NaN   \n",
       "\n",
       "  skill  difficulty  aptitude  games_total   ...     op_p2_pose_y9  skill_NC  \\\n",
       "0   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "1   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "2   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "3   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "4   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "\n",
       "   skill_OS  skill_EM  diff_1  diff_2  diff_3  diff_4  diff_5  no_game  \n",
       "0         0         0       0       0       0       0       0        1  \n",
       "1         0         0       0       0       0       0       0        1  \n",
       "2         0         0       0       0       0       0       0        1  \n",
       "3         0         0       0       0       0       0       0        1  \n",
       "4         0         0       0       0       0       0       0        1  \n",
       "\n",
       "[5 rows x 1572 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "\n",
    "# transcriptions\n",
    "data = data.drop(columns=['transcript_spk_0', 'transcript_spk_1', 'transcript_spk_2'])\n",
    "\n",
    "# raw ros messages\n",
    "data = data.drop(columns=['ros_PARTICIPANT_STATE', 'ros_ROBOT_STATE'])\n",
    "\n",
    "# more for counting purposes\n",
    "data = data.drop(columns=['game_start', 'game_correct', 'game_incorrect', 'mistake_made'])\n",
    "\n",
    "data = data.drop(columns=['participant', 'session_date'])\n",
    "\n",
    "# use one-hot encoded difficulty and skill, don't use activity for now\n",
    "data = data.drop(columns=['difficulty', 'skill', 'activity', 'of_face_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Face/Open-Pose Columns? \n",
    "# Feature Dictionary Documentation here: https://docs.google.com/document/d/1RSygoLwsM1PKEIOoqDOaEo3lRBZBLZJuzbMSY5K_6zA/edit?usp=sharing\n",
    "\n",
    "only_ofop = []\n",
    "performance = []\n",
    "for i in data.columns:\n",
    "    # open face/open pose columns begin with of_ or op_\n",
    "    if 'op_' in i or 'of_' in i:\n",
    "        only_ofop.append(i)\n",
    "    else:\n",
    "        performance.append(i)\n",
    "        \n",
    "only_ofop.remove('of_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    139463\n",
      "0.0    120473\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.5365282223316509\n",
      "0 0.4634717776683491\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All OF/OP + Performance\n",
    "2. Performance ONLY\n",
    "3. All OF/OP ONLY\n",
    "4. Performance + Handpicked OF/OP (from Caitlyn's intuition)\n",
    "5. Performance + Selected OF/OP (from Feature Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: keep timestamp and session_num until right before running the model in all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 1: All OF/OP + Performance\n",
    "\n",
    "FS1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 2: Performance ONLY\n",
    "\n",
    "print(performance)\n",
    "\n",
    "FS2 = data[performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 3: OF/OP ONLY  \n",
    "\n",
    "only_ofop.append('timestamp')\n",
    "only_ofop.append('session_num')\n",
    "only_ofop.append('engagement')\n",
    "\n",
    "FS3 = data[only_ofop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 4: Performance + Handpicked OF/OP\n",
    "\n",
    "hand_picked = ['confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'gaze_angle_x', 'gaze_angle_y']\n",
    "for i,c in enumerate(hand_picked):\n",
    "    hand_picked[i] = 'of_' + c\n",
    "hand_picked.append('op_Number of People')\n",
    "\n",
    "for i in performance:\n",
    "    hand_picked.append(i)\n",
    "\n",
    "FS4 = data[hand_picked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 5: Performance + Selected OF/OP\n",
    "\n",
    "selected_ofop = ['of_AU04_c',   'of_AU06_c',    'of_AU07_c',    'of_AU14_c',    'of_AU15_c',    'of_AU25_c',    'of_confidence',    'of_frame',    'of_success',    'of_timestamp', 'op_p1_face_c25',    'op_p1_face_c43',    'op_p1_face_c44',    'op_p1_face_c45',    'op_p1_face_c46',    'op_p1_face_y7',    'op_p1_face_y8',    'op_p1_pose_c0',    'op_p1_pose_c15',    'op_p1_pose_c16']\n",
    "\n",
    "for i in performance:\n",
    "    selected_ofop.append(i)\n",
    "\n",
    "FS5 = data[selected_ofop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Test Split (for chosen Feature Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Shuffle 70-30\n",
    "2. Train on Earlier Sessions, Test on Later Sessions 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE FEATURE SET\n",
    "\n",
    "FS = FS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Shuffle Data if not temporal model\n",
    "\n",
    "FS = FS.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split 1: Random Shuffle 70-30\n",
    "\n",
    "y1 = FS['engagement']\n",
    "X1 = FS.drop(columns=['timestamp', 'session_num', 'engagement'])\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split 2: Train on Earlier Sessions, Test on Later Sessions\n",
    "\n",
    "session_threshold = 8 # train on sessions <= 8, test on sessions > 8\n",
    "\n",
    "train = FS[(FS['session_num'] <= 8.0)] \n",
    "test = FS[(FS['session_num'] > 8)]\n",
    "\n",
    "# drop columns needed for split\n",
    "train2 = train.drop(columns=['session_num', 'timestamp'])\n",
    "test2 = test.drop(columns=['session_num', 'timestamp'])\n",
    "\n",
    "X_train2 = train2.drop(columns=['engagement'])\n",
    "y_train2 = train2['engagement']\n",
    "\n",
    "X_test2 = test2.drop(columns=['engagement'])\n",
    "y_test2 = test2['engagement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "size_batch = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               199040    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 209,409\n",
      "Trainable params: 209,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# NN Model 1 for FS1 (all OF/OP)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=128, input_dim=len(X_train1.columns))) # Should have 1554 features in FS1\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', # specify crossentropy cost function \n",
    "              optimizer='sgd', # stochastic gradient descent\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a28bfb9b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1, epochs=num_epochs, batch_size=size_batch, verbose=0, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77981/77981 [==============================] - 5s 68us/step\n",
      "[0.2251311304949324, 0.9042587296852153]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test1, y_test1, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict_proba(X_test1)\n",
    "pred = model.predict_classes(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9713936654596413\n",
      "Accuracy: 0.9042587296905656\n",
      "[[33686  2642]\n",
      " [ 4824 36829]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90     36328\n",
      "         1.0       0.93      0.88      0.91     41653\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     77981\n",
      "   macro avg       0.90      0.91      0.90     77981\n",
      "weighted avg       0.91      0.90      0.90     77981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC:\",roc_auc_score(y_test1, scores)) \n",
    "print(\"Accuracy:\",accuracy_score(y_test1, pred))\n",
    "print(metrics.confusion_matrix(y_test1, pred))\n",
    "print(metrics.classification_report(y_test1, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2bdc0630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, epochs=num_epochs, batch_size=size_batch, verbose=0, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105092/105092 [==============================] - 7s 71us/step\n",
      "[0.2784716728270049, 0.8841586419518136]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test2, y_test2, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict_proba(X_test2)\n",
    "pred = model.predict_classes(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9674745298642521\n",
      "Accuracy: 0.8841586419518136\n",
      "[[62076  2501]\n",
      " [ 9673 30842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91     64577\n",
      "         1.0       0.92      0.76      0.84     40515\n",
      "\n",
      "   micro avg       0.88      0.88      0.88    105092\n",
      "   macro avg       0.90      0.86      0.87    105092\n",
      "weighted avg       0.89      0.88      0.88    105092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC:\",roc_auc_score(y_test2, scores)) \n",
    "print(\"Accuracy:\",accuracy_score(y_test2, pred))\n",
    "print(metrics.confusion_matrix(y_test2, pred))\n",
    "print(metrics.classification_report(y_test2, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
