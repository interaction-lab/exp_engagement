{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Engagement Classifcation Model\n",
    "\n",
    "# ToDo/Models to run here: https://docs.google.com/document/d/18EJpFesMEl9Q7C1AZzDeq6uy7c8tDMvEJ_j58-MmiBI/edit?usp=sharing\n",
    "# Use p8_data_processed.csv here: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Warning: this will probably take some time\n",
    "# Adjust file path based on your computer\n",
    "\n",
    "file = '../../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/p8_data_processed.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>session_num</th>\n",
       "      <th>session_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>engagement</th>\n",
       "      <th>activity</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>aptitude</th>\n",
       "      <th>games_total</th>\n",
       "      <th>...</th>\n",
       "      <th>op_p2_pose_y9</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  session_num session_date  timestamp  engagement  activity  \\\n",
       "0          8.0          1.0   2018-06-07   0.000000         1.0       NaN   \n",
       "1          8.0          1.0   2018-06-07   0.033333         1.0       NaN   \n",
       "2          8.0          1.0   2018-06-07   0.066667         1.0       NaN   \n",
       "3          8.0          1.0   2018-06-07   0.100000         1.0       NaN   \n",
       "4          8.0          1.0   2018-06-07   0.133333         1.0       NaN   \n",
       "\n",
       "  skill  difficulty  aptitude  games_total   ...     op_p2_pose_y9  skill_NC  \\\n",
       "0   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "1   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "2   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "3   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "4   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "\n",
       "   skill_OS  skill_EM  diff_1  diff_2  diff_3  diff_4  diff_5  no_game  \n",
       "0         0         0       0       0       0       0       0        1  \n",
       "1         0         0       0       0       0       0       0        1  \n",
       "2         0         0       0       0       0       0       0        1  \n",
       "3         0         0       0       0       0       0       0        1  \n",
       "4         0         0       0       0       0       0       0        1  \n",
       "\n",
       "[5 rows x 1572 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "\n",
    "# transcriptions\n",
    "data = data.drop(columns=['transcript_spk_0', 'transcript_spk_1', 'transcript_spk_2'])\n",
    "\n",
    "# raw ros messages\n",
    "data = data.drop(columns=['ros_PARTICIPANT_STATE', 'ros_ROBOT_STATE'])\n",
    "\n",
    "# more for counting purposes\n",
    "data = data.drop(columns=['game_start', 'game_correct', 'game_incorrect', 'mistake_made'])\n",
    "\n",
    "data = data.drop(columns=['participant', 'session_date'])\n",
    "\n",
    "# use one-hot encoded difficulty and skill, don't use activity for now\n",
    "data = data.drop(columns=['difficulty', 'skill', 'activity', 'of_face_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Face/Open-Pose Columns? \n",
    "# Feature Dictionary Documentation here: https://docs.google.com/document/d/1RSygoLwsM1PKEIOoqDOaEo3lRBZBLZJuzbMSY5K_6zA/edit?usp=sharing\n",
    "\n",
    "only_ofop = []\n",
    "performance = []\n",
    "for i in data.columns:\n",
    "    # open face/open pose columns begin with of_ or op_\n",
    "    if 'op_' in i or 'of_' in i:\n",
    "        only_ofop.append(i)\n",
    "    else:\n",
    "        performance.append(i)\n",
    "        \n",
    "only_ofop.remove('of_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    139463\n",
      "0.0    120473\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.5365282223316509\n",
      "0 0.4634717776683491\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All OF/OP + Performance\n",
    "2. Performance ONLY\n",
    "3. All OF/OP ONLY\n",
    "4. Performance + Handpicked OF/OP (from Caitlyn's intuition)\n",
    "5. Performance + Selected OF/OP (from Feature Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: keep timestamp and session_num until right before running the model in all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 1: All OF/OP + Performance\n",
    "\n",
    "FS1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_num', 'timestamp', 'engagement', 'aptitude', 'games_total', 'games_session', 'mistakes_total', 'mistakes_session', 'mistakes_game', 'ts_robot_talked', 'ts_game_start', 'ts_attempt', 'skill_NC', 'skill_OS', 'skill_EM', 'diff_1', 'diff_2', 'diff_3', 'diff_4', 'diff_5', 'no_game']\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 2: Performance ONLY\n",
    "\n",
    "print(performance)\n",
    "\n",
    "FS2 = data[performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 3: OF/OP ONLY  \n",
    "\n",
    "only_ofop.append('timestamp')\n",
    "only_ofop.append('session_num')\n",
    "only_ofop.append('engagement')\n",
    "\n",
    "FS3 = data[only_ofop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 4: Performance + Handpicked OF/OP\n",
    "\n",
    "hand_picked = ['confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'gaze_angle_x', 'gaze_angle_y']\n",
    "for i,c in enumerate(hand_picked):\n",
    "    hand_picked[i] = 'of_' + c\n",
    "hand_picked.append('op_Number of People')\n",
    "\n",
    "for i in performance:\n",
    "    hand_picked.append(i)\n",
    "\n",
    "FS4 = data[hand_picked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 5: Performance + Selected OF/OP\n",
    "\n",
    "selected_ofop = ['of_AU04_c',   'of_AU06_c',    'of_AU07_c',    'of_AU14_c',    'of_AU15_c',    'of_AU25_c',    'of_confidence',    'of_frame',    'of_success',    'of_timestamp', 'op_p1_face_c25',    'op_p1_face_c43',    'op_p1_face_c44',    'op_p1_face_c45',    'op_p1_face_c46',    'op_p1_face_y7',    'op_p1_face_y8',    'op_p1_pose_c0',    'op_p1_pose_c15',    'op_p1_pose_c16']\n",
    "\n",
    "for i in performance:\n",
    "    selected_ofop.append(i)\n",
    "\n",
    "FS5 = data[selected_ofop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Test Split (for chosen Feature Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HMM: train on a session, test on another session\n",
    "Try with sessions 6 and 7 (same day, similar engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE FEATURE SET\n",
    "\n",
    "FS = FS5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "FS = FS.sort_values(['session_num', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "train = FS[(FS['session_num'] == 6)] \n",
    "test = FS[(FS['session_num'] == 7)]\n",
    "\n",
    "# drop columns needed for split\n",
    "train2 = train.drop(columns=['session_num', 'timestamp'])\n",
    "test2 = test.drop(columns=['session_num', 'timestamp'])\n",
    "\n",
    "X_train2 = train2.drop(columns=['engagement'])\n",
    "y_train2 = train2['engagement']\n",
    "\n",
    "X_test2 = test2.drop(columns=['engagement'])\n",
    "y_test2 = test2['engagement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Use X_train2, y_train2, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "# given model and sequence S, what is optimal hidden state sequence \n",
    "\n",
    "\n",
    "# 3 questions from HMM:\n",
    "# (1) given model, what is likelihood of sequence S happening?\n",
    "# (2) given model and sequence S, what is optimal hidden state sequence?\n",
    "# (3) given sequence S and # of hidden states, what is optimal model to maximize probability of S?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fit the hmm\n",
    "def fitHMM(D):\n",
    "    # fit Gaussian HMM to the given Data\n",
    "    model = GaussianHMM(n_components=2, n_iter=1000, algorithm='viterbi').fit([D])\n",
    "     \n",
    "    # classify each observation as state 0 or 1\n",
    "    hidden_states = model.predict(D)\n",
    " \n",
    "    # find parameters of Gaussian HMM\n",
    "    mus = np.array(model.means_)\n",
    "    sigmas = np.array(np.sqrt(np.array([np.diag(model.covars_[0]),np.diag(model.covars_[1])])))\n",
    "    P = np.array(model.transmat_)\n",
    " \n",
    "    # find log-likelihood of Gaussian HMM\n",
    "    logProb = model.score(D)\n",
    " \n",
    "    return model, hidden_states, mus, sigmas, P, logProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS2 Train/Test/Split 1\n",
    "FS2_matrix_test1 = X_train1.values\n",
    "FS2_model_1, FS2_hidden_states_1, FS2_mus_1, FS2_sigmas_1, FS2_P_1, FS2_logProb_1 = fitHMM(FS2_matrix_test1)\n",
    "\n",
    "#FS2 Train/Test/Split 2\n",
    "FS2_matrix_test2 = X_train2.values\n",
    "FS2_model_2, FS2_hidden_states_2, FS2_mus_2, FS2_sigmas_2, FS2_P_2, FS2_logProb_2 = fitHMM(FS2_matrix_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate FS2 HMM\n",
    "FS2_pred1 = FS2_model_1.predict(X_test1.values)\n",
    "scores1 = FS2_model_1.predict_proba(X_test1.values)\n",
    "scores1 = scores1[:, 1]\n",
    "\n",
    "print(\"Accuracy for FS2 Split 1:\",accuracy_score(y_test1, FS2_pred1))\n",
    "print(\"AUC:\",roc_auc_score(y_test1, scores1)) \n",
    "print(metrics.confusion_matrix(y_test1, FS2_pred1))\n",
    "print(metrics.classification_report(y_test1, FS2_pred1))\n",
    "\n",
    "FS2_pred2 = FS2_model_2.predict(X_test2.values)\n",
    "scores2 = FS2_model_2.predict_proba(X_test2.values)\n",
    "scores2 = scores2[: ,1]\n",
    "print(\"Accuracy for FS2 Split 2:\",accuracy_score(y_test2, FS2_pred2))\n",
    "print(\"AUC:\",roc_auc_score(y_test2, scores2)) \n",
    "print(metrics.confusion_matrix(y_test2, FS2_pred2))\n",
    "print(metrics.classification_report(y_test2, FS2_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS4 Train/Test/Split 1\n",
    "FS4_matrix_test1 = X_train1.values\n",
    "FS4_model_1, FS4_hidden_states_1, FS4_mus_1, FS4_sigmas_1, FS4_P_1, FS4_logProb_1 = fitHMM(FS4_matrix_test1)\n",
    "\n",
    "#FS4 Train/Test/Split 2\n",
    "FS4_matrix_test2 = X_train2.values\n",
    "FS4_model_2, FS4_hidden_states_2, FS4_mus_2, FS4_sigmas_2, FS4_P_2, FS4_logProb_2 = fitHMM(FS4_matrix_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate FS4 HMM\n",
    "FS4_pred1 = FS4_model_1.predict(X_test1.values)\n",
    "scores1 = FS4_model_1.predict_proba(X_test1.values)\n",
    "scores1 = scores1[:, 1]\n",
    "\n",
    "print(\"Accuracy for FS4 Split 1:\",accuracy_score(y_test1, FS4_pred1))\n",
    "print(\"AUC:\",roc_auc_score(y_test1, scores1)) \n",
    "print(metrics.confusion_matrix(y_test1, FS4_pred1))\n",
    "print(metrics.classification_report(y_test1, FS4_pred1))\n",
    "\n",
    "FS4_pred2 = FS4_model_2.predict(X_test2.values)\n",
    "scores2 = FS4_model_2.predict_proba(X_test2.values)\n",
    "scores2 = scores2[: ,1]\n",
    "print(\"Accuracy for FS4 Split 2:\",accuracy_score(y_test2, FS4_pred2))\n",
    "print(\"AUC:\",roc_auc_score(y_test2, scores2)) \n",
    "print(metrics.confusion_matrix(y_test2, FS4_pred2))\n",
    "print(metrics.classification_report(y_test2, FS4_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Set 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS5 Train/Test/Split 1\n",
    "FS5_matrix_test1 = X_train1.values\n",
    "FS5_model_1, FS5_hidden_states_1, FS5_mus_1, FS5_sigmas_1, FS5_P_1, FS5_logProb_1 = fitHMM(FS5_matrix_test1)\n",
    "\n",
    "#FS5 Train/Test/Split 2\n",
    "FS5_matrix_test2 = X_train2.values\n",
    "FS5_model_2, FS5_hidden_states_2, FS5_mus_2, FS5_sigmas_2, FS5_P_2, FS5_logProb_2 = fitHMM(FS5_matrix_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate FS5 HMM\n",
    "FS5_pred1 = FS5_model_1.predict(X_test1.values)\n",
    "scores1 = FS5_model_1.predict_proba(X_test1.values)\n",
    "scores1 = scores1[:, 1]\n",
    "\n",
    "print(\"Accuracy for FS5 Split 1:\",accuracy_score(y_test1, FS5_pred1))\n",
    "print(\"AUC:\",roc_auc_score(y_test1, scores1)) \n",
    "print(metrics.confusion_matrix(y_test1, FS5_pred1))\n",
    "print(metrics.classification_report(y_test1, FS5_pred1))\n",
    "\n",
    "FS5_pred2 = FS5_model_2.predict(X_test2.values)\n",
    "scores2 = FS5_model_2.predict_proba(X_test2.values)\n",
    "scores2 = scores2[: ,1]\n",
    "print(\"Accuracy for FS5 Split 2:\",accuracy_score(y_test2, FS5_pred2))\n",
    "print(\"AUC:\",roc_auc_score(y_test2, scores2)) \n",
    "print(metrics.confusion_matrix(y_test2, FS5_pred2))\n",
    "print(metrics.classification_report(y_test2, FS5_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS1 Train/Test/Split 1\n",
    "FS1_matrix_test1 = X_train1.values\n",
    "FS1_model_1, FS1_hidden_states_1, FS1_mus_1, FS1_sigmas_1, FS1_P_1, FS1_logProb_1 = fitHMM(FS1_matrix_test1)\n",
    "\n",
    "#FS1 Train/Test/Split 2\n",
    "FS1_matrix_test2 = X_train2.values\n",
    "FS1_model_2, FS1_hidden_states_2, FS1_mus_2, FS1_sigmas_2, FS1_P_2, FS1_logProb_2 = fitHMM(FS1_matrix_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate FS1 HMM\n",
    "FS1_pred1 = FS1_model_1.predict(X_test1.values)\n",
    "scores1 = FS1_model_1.predict_proba(X_test1.values)\n",
    "scores1 = scores1[:, 1]\n",
    "\n",
    "print(\"Accuracy for FS1 Split 1:\",accuracy_score(y_test1, FS1_pred1))\n",
    "print(\"AUC:\",roc_auc_score(y_test1, scores1)) \n",
    "print(metrics.confusion_matrix(y_test1, FS1_pred1))\n",
    "print(metrics.classification_report(y_test1, FS1_pred1))\n",
    "\n",
    "FS1_pred2 = FS1_model_2.predict(X_test2.values)\n",
    "scores2 = FS1_model_2.predict_proba(X_test2.values)\n",
    "scores2 = scores2[: ,1]\n",
    "print(\"Accuracy for FS1 Split 2:\",accuracy_score(y_test2, FS1_pred2))\n",
    "print(\"AUC:\",roc_auc_score(y_test2, scores2)) \n",
    "print(metrics.confusion_matrix(y_test2, FS1_pred2))\n",
    "print(metrics.classification_report(y_test2, FS1_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FS3 Train/Test/Split 1\n",
    "FS3_matrix_test1 = X_train1.values\n",
    "FS3_model_1 = GaussianHMM(n_components=2, n_iter=1000, algorithm='viterbi').fit([FS3_matrix_test1])\n",
    "\n",
    "#FS3 Train/Test/Split 2\n",
    "FS3_matrix_test2 = X_train2.values\n",
    "FS3_model_2 = GaussianHMM(n_components=2, n_iter=1000, algorithm='viterbi').fit([FS3_matrix_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
