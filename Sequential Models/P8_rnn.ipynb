{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Notebook for Engagement Classifcation Model\n",
    "\n",
    "# ToDo/Models to run here: https://docs.google.com/document/d/18EJpFesMEl9Q7C1AZzDeq6uy7c8tDMvEJ_j58-MmiBI/edit?usp=sharing\n",
    "# Use p8_data_processed.csv here: https://drive.google.com/drive/folders/19aJUAlkTMz7PcZE1q4hogFkjVtwYGcMT\n",
    "# Upload code to help-seeking github: https://github.com/interaction-lab/help_seeking\n",
    "# Record model results here: https://docs.google.com/spreadsheets/d/16ye54fSSEuAuDL_j56UIeDB-rIIrxq_kPbtyPRQOrVI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (6,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Warning: this will probably take some time\n",
    "# Adjust file path based on your computer\n",
    "\n",
    "file = '../../../Google Drive File Stream/My Drive/USC Expeditions Year 5/Analysis/Help-Seeking/Data/p8_data_processed.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>session_num</th>\n",
       "      <th>session_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>engagement</th>\n",
       "      <th>activity</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>aptitude</th>\n",
       "      <th>games_total</th>\n",
       "      <th>...</th>\n",
       "      <th>op_p2_pose_y9</th>\n",
       "      <th>skill_NC</th>\n",
       "      <th>skill_OS</th>\n",
       "      <th>skill_EM</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>diff_3</th>\n",
       "      <th>diff_4</th>\n",
       "      <th>diff_5</th>\n",
       "      <th>no_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  session_num session_date  timestamp  engagement  activity  \\\n",
       "0          8.0          1.0   2018-06-07   0.000000         1.0       NaN   \n",
       "1          8.0          1.0   2018-06-07   0.033333         1.0       NaN   \n",
       "2          8.0          1.0   2018-06-07   0.066667         1.0       NaN   \n",
       "3          8.0          1.0   2018-06-07   0.100000         1.0       NaN   \n",
       "4          8.0          1.0   2018-06-07   0.133333         1.0       NaN   \n",
       "\n",
       "  skill  difficulty  aptitude  games_total   ...     op_p2_pose_y9  skill_NC  \\\n",
       "0   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "1   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "2   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "3   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "4   NaN         NaN       0.5          0.0   ...               0.0         0   \n",
       "\n",
       "   skill_OS  skill_EM  diff_1  diff_2  diff_3  diff_4  diff_5  no_game  \n",
       "0         0         0       0       0       0       0       0        1  \n",
       "1         0         0       0       0       0       0       0        1  \n",
       "2         0         0       0       0       0       0       0        1  \n",
       "3         0         0       0       0       0       0       0        1  \n",
       "4         0         0       0       0       0       0       0        1  \n",
       "\n",
       "[5 rows x 1572 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "\n",
    "# transcriptions\n",
    "data = data.drop(columns=['transcript_spk_0', 'transcript_spk_1', 'transcript_spk_2'])\n",
    "\n",
    "# raw ros messages\n",
    "data = data.drop(columns=['ros_PARTICIPANT_STATE', 'ros_ROBOT_STATE'])\n",
    "\n",
    "# more for counting purposes\n",
    "data = data.drop(columns=['game_start', 'game_correct', 'game_incorrect', 'mistake_made'])\n",
    "\n",
    "data = data.drop(columns=['participant', 'session_date'])\n",
    "\n",
    "# use one-hot encoded difficulty and skill, don't use activity for now\n",
    "data = data.drop(columns=['difficulty', 'skill', 'activity', 'of_face_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Face/Open-Pose Columns? \n",
    "# Feature Dictionary Documentation here: https://docs.google.com/document/d/1RSygoLwsM1PKEIOoqDOaEo3lRBZBLZJuzbMSY5K_6zA/edit?usp=sharing\n",
    "\n",
    "only_ofop = []\n",
    "performance = []\n",
    "for i in data.columns:\n",
    "    # open face/open pose columns begin with of_ or op_\n",
    "    if 'op_' in i or 'of_' in i:\n",
    "        only_ofop.append(i)\n",
    "    else:\n",
    "        performance.append(i)\n",
    "        \n",
    "only_ofop.remove('of_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    139463\n",
      "0.0    120473\n",
      "Name: engagement, dtype: int64\n",
      "\n",
      "1 0.5365282223316509\n",
      "0 0.4634717776683491\n"
     ]
    }
   ],
   "source": [
    "# Label Analysis\n",
    "\n",
    "print(data['engagement'].value_counts())\n",
    "print()\n",
    "\n",
    "print(1,data['engagement'].value_counts()[1]/sum(data['engagement'].value_counts()))\n",
    "print(0,data['engagement'].value_counts()[0]/sum(data['engagement'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All OF/OP + Performance\n",
    "2. Performance ONLY\n",
    "3. All OF/OP ONLY\n",
    "4. Performance + Handpicked OF/OP (from Caitlyn's intuition)\n",
    "5. Performance + Selected OF/OP (from Feature Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: keep timestamp and session_num until right before running the model in all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 1: All OF/OP + Performance\n",
    "\n",
    "FS1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_num', 'timestamp', 'engagement', 'aptitude', 'games_total', 'games_session', 'mistakes_total', 'mistakes_session', 'mistakes_game', 'ts_robot_talked', 'ts_game_start', 'ts_attempt', 'skill_NC', 'skill_OS', 'skill_EM', 'diff_1', 'diff_2', 'diff_3', 'diff_4', 'diff_5', 'no_game']\n"
     ]
    }
   ],
   "source": [
    "# Feature Set 2: Performance ONLY\n",
    "\n",
    "print(performance)\n",
    "\n",
    "FS2 = data[performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 3: OF/OP ONLY  \n",
    "\n",
    "only_ofop.append('timestamp')\n",
    "only_ofop.append('session_num')\n",
    "only_ofop.append('engagement')\n",
    "\n",
    "FS3 = data[only_ofop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 4: Performance + Handpicked OF/OP\n",
    "\n",
    "hand_picked = ['confidence', 'success', 'gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z', 'gaze_angle_x', 'gaze_angle_y']\n",
    "for i,c in enumerate(hand_picked):\n",
    "    hand_picked[i] = 'of_' + c\n",
    "hand_picked.append('op_Number of People')\n",
    "\n",
    "for i in performance:\n",
    "    hand_picked.append(i)\n",
    "\n",
    "FS4 = data[hand_picked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set 5: Performance + Selected OF/OP\n",
    "\n",
    "selected_ofop = ['of_AU04_c',   'of_AU06_c',    'of_AU07_c',    'of_AU14_c',    'of_AU15_c',    'of_AU25_c',    'of_confidence',    'of_frame',    'of_success',    'of_timestamp', 'op_p1_face_c25',    'op_p1_face_c43',    'op_p1_face_c44',    'op_p1_face_c45',    'op_p1_face_c46',    'op_p1_face_y7',    'op_p1_face_y8',    'op_p1_pose_c0',    'op_p1_pose_c15',    'op_p1_pose_c16']\n",
    "\n",
    "for i in performance:\n",
    "    selected_ofop.append(i)\n",
    "\n",
    "FS5 = data[selected_ofop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Windows for RNN (for chosen Feature Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE FEATURE SET, Window Size\n",
    "\n",
    "FS = FS1\n",
    "\n",
    "# window_size = # of frames to feed into an RNN at a time\n",
    "window_size = 50 \n",
    "\n",
    "session_threshold = 8 # train on sessions <= 8, test on sessions > 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Data (Temporal Model)\n",
    "\n",
    "FS = FS.sort_values(['session_num', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Windows, mapped by session\n",
    "# throw away end/remainder of session < 50 frames\n",
    "\n",
    "windows = []\n",
    "X_train2 = []\n",
    "y_train2 = []\n",
    "X_test2 = []\n",
    "y_test2 = []\n",
    "\n",
    "curr_session = -1\n",
    "window_start = -1\n",
    "curr_window = -1\n",
    "\n",
    "for i,r in FS.iterrows():\n",
    "    this_session = r['session_num']\n",
    "    \n",
    "    # we've encountered a new session\n",
    "    if curr_session != this_session:\n",
    "        # ignore remainder window\n",
    "        curr_session = this_session\n",
    "        window_start = i\n",
    "        curr_window = 1\n",
    "        continue\n",
    "    \n",
    "    # we've found a complete window\n",
    "    if curr_window == window_size - 1:\n",
    "        to_add = FS[window_start:i+1]\n",
    "        to_add = to_add.drop(columns=['session_num', 'timestamp'])\n",
    "        \n",
    "        windows.append(to_add)\n",
    "        if (curr_session <= session_threshold):\n",
    "            y_train2.append(to_add['engagement'])\n",
    "            X_train2.append(to_add.drop(columns=['engagement']))\n",
    "        else:\n",
    "            y_test2.append(to_add['engagement'])\n",
    "            X_test2.append(to_add.drop(columns=['engagement']))\n",
    "            \n",
    "        window_start = i+1\n",
    "        curr_window = 0\n",
    "        continue \n",
    "        \n",
    "    curr_window += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle Windows\n",
    "\n",
    "random.shuffle(windows)\n",
    "\n",
    "y1 = []\n",
    "X1 = []\n",
    "\n",
    "for i in windows:\n",
    "    y1.append(i['engagement'])\n",
    "    X1.append(i.drop(columns=['engagement']))\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Your Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For chosen feature set, run on both Train-Test Splits\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers import Dropout, concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import metrics\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3635"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/anaconda3/envs/caispp/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=False, input_shape=(50, 1554))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                414464    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 417,714\n",
      "Trainable params: 417,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# At this point, each individual training sample is now a sequence of word embedding vectors\n",
    "\n",
    "num_features = X_train1[0].shape[1]\n",
    "\n",
    "model.add(LSTM(64, input_length=window_size, input_dim=num_features, return_sequences = False)) #return_sequences: if multiple LSTM layers\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "# Dense 2 (final vote)\n",
    "model.add(Dense(50, activation = 'sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "LOSS = 'binary_crossentropy' #classifying between 0 and 1\n",
    "OPTIMIZER = 'rmsprop' #RMSprop typically works better for RNNs per Keras\n",
    "\n",
    "model.compile(loss = LOSS, optimizer = OPTIMIZER, metrics = [metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 3635 arrays: [array([[0.3       , 0.09803922, 0.3125    , ..., 0.        , 0.        ,\n        0.        ],\n       [0.3       , 0.09803922, 0.3125    , ..., 0.        , 0.        ,\n        0.        ],\n       [0.3...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-dc02449783cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_split =.2)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 3635 arrays: [array([[0.3       , 0.09803922, 0.3125    , ..., 0.        , 0.        ,\n        0.        ],\n       [0.3       , 0.09803922, 0.3125    , ..., 0.        , 0.        ,\n        0.        ],\n       [0.3..."
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model.fit(X_train1, y_train1, \n",
    "          epochs = EPOCHS, \n",
    "          batch_size = BATCH_SIZE, \n",
    "          validation_split =.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
