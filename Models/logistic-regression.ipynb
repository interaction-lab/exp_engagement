{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, Split, Train set, Test set, Include x% of test participant in train, Feature Set, Preprocessing, Algorithm\n",
    "# String, Float (0-1), List, List, Float (0-1), String, String, String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset, split, train, test, includex, features, preprocessing):\n",
    "    \n",
    "    if(split>0):\n",
    "        if(dataset=='regular'):\n",
    "            path = 'data/Master/' + item + '_master.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:]\n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "        elif(dataset=='smooth'):\n",
    "            path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:]\n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "        else:\n",
    "            path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "            tdf = pd.read_csv(path)\n",
    "            length = int(split*len(tdf))\n",
    "            train_df = tdf.iloc[:length,:]\n",
    "            test_df = tdf.iloc[length:,:] \n",
    "            #test_df = test_df.drop(['engagement'],axis=1)\n",
    "    else:\n",
    "        # Training Data\n",
    "        train_df = pd.DataFrame()\n",
    "        for item in train:\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                train_df = train_df.append(tdf)       \n",
    "\n",
    "        # Include x% of Test Participants Data\n",
    "        if(includex>0):\n",
    "            item = test[0]\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                length = int(includex*len(tdf))\n",
    "                tdf = tdf.iloc[:length,:]\n",
    "                train_df = train_df.append(tdf)      \n",
    "\n",
    "        # Test Data\n",
    "        test_df = pd.DataFrame()\n",
    "        for item in test:\n",
    "            if(dataset=='regular'):\n",
    "                path = 'data/Master/' + item + '_master.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)\n",
    "            elif(dataset=='smooth'):\n",
    "                path = 'data/Master_Smooth/' + item + '_master_smooth.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)\n",
    "            else:\n",
    "                path = 'data/Master_Window/' + item + '_master_window.csv'\n",
    "                tdf = pd.read_csv(path)\n",
    "                #tdf = tdf.drop(['engagement'],axis=1)\n",
    "                test_df = test_df.append(tdf)   \n",
    "    \n",
    "    y_train = train_df['engagement']\n",
    "    y_test = test_df['engagement']\n",
    "    X_train = train_df.drop(['engagement'],axis = 1)\n",
    "    X_test = test_df.drop(['engagement'],axis = 1)\n",
    "    \n",
    "    \n",
    "    if(features == 'variance_threshold'):\n",
    "        selector = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "        selector.fit(X_train)\n",
    "        X_train = selector.transform(X_train)\n",
    "        X_test = selector.transform(X_test)\n",
    "        \n",
    "    if(preprocessing == 'standard'):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    elif(preprocessing == 'minmax'):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    imputer.fit(X_train)\n",
    "    X_train = imputer.transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_test, y_train, y_test, algorithm):\n",
    "    if(algorithm == 'logistic'):\n",
    "        clf = LogisticRegression(solver='lbfgs') \n",
    "    elif(algorithm == 'naivebayes'):\n",
    "        clf = GaussianNB()\n",
    "    else:\n",
    "        clf = LinearSVC()\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    try:\n",
    "        scores = clf.decision_function(X_test)\n",
    "    except:\n",
    "        scores = clf.predict_proba(X_test)\n",
    "        sd = pd.DataFrame(scores)\n",
    "        scores = sd[1]\n",
    "    #print scores\n",
    "    # Accuracy:\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test,pred))\n",
    "    print(metrics.classification_report(y_test,pred))\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "    try:\n",
    "        print(\"AUC:\",roc_auc_score(y_test, scores)) \n",
    "    except:\n",
    "        print(\"AUC undefinied, only 1 class in test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p5,p7]\n",
    "\n",
    "- test = [p9]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.769933894854061)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80    191811\n",
      "           1       0.84      0.64      0.73    174575\n",
      "\n",
      "   micro avg       0.77      0.77      0.77    366386\n",
      "   macro avg       0.79      0.76      0.76    366386\n",
      "weighted avg       0.78      0.77      0.77    366386\n",
      "\n",
      "[[170880  20931]\n",
      " [ 63362 111213]]\n",
      "('AUC:', 0.8804615392840552)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.7099643545331973)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70    191811\n",
      "           1       0.67      0.79      0.72    174575\n",
      "\n",
      "   micro avg       0.71      0.71      0.71    366386\n",
      "   macro avg       0.72      0.71      0.71    366386\n",
      "weighted avg       0.72      0.71      0.71    366386\n",
      "\n",
      "[[122523  69288]\n",
      " [ 36977 137598]]\n",
      "('AUC:', 0.7713753144482804)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.7929806269890225)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82    191811\n",
      "           1       0.84      0.70      0.76    174575\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    366386\n",
      "   macro avg       0.80      0.79      0.79    366386\n",
      "weighted avg       0.80      0.79      0.79    366386\n",
      "\n",
      "[[169033  22778]\n",
      " [ 53071 121504]]\n",
      "('AUC:', 0.8912122030286339)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.7155704639369408)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69    191811\n",
      "           1       0.66      0.84      0.74    174575\n",
      "\n",
      "   micro avg       0.72      0.72      0.72    366386\n",
      "   macro avg       0.73      0.72      0.71    366386\n",
      "weighted avg       0.73      0.72      0.71    366386\n",
      "\n",
      "[[115681  76130]\n",
      " [ 28081 146494]]\n",
      "('AUC:', 0.785255480254516)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.7900814939186699)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.91      0.82     12792\n",
      "         1.0       0.87      0.66      0.75     11627\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     24419\n",
      "   macro avg       0.81      0.78      0.78     24419\n",
      "weighted avg       0.80      0.79      0.79     24419\n",
      "\n",
      "[[11613  1179]\n",
      " [ 3947  7680]]\n",
      "('AUC:', 0.8965425760370034)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.579671567222245)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.65      0.62     12792\n",
      "         1.0       0.57      0.50      0.53     11627\n",
      "\n",
      "   micro avg       0.58      0.58      0.58     24419\n",
      "   macro avg       0.58      0.58      0.58     24419\n",
      "weighted avg       0.58      0.58      0.58     24419\n",
      "\n",
      "[[8326 4466]\n",
      " [5798 5829]]\n",
      "('AUC:', 0.636388472885)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.8141611040583152)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.90      0.84     12792\n",
      "         1.0       0.87      0.72      0.79     11627\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     24419\n",
      "   macro avg       0.82      0.81      0.81     24419\n",
      "weighted avg       0.82      0.81      0.81     24419\n",
      "\n",
      "[[11536  1256]\n",
      " [ 3282  8345]]\n",
      "('AUC:', 0.9083822546914132)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.5810639256316803)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.64      0.62     12792\n",
      "         1.0       0.57      0.52      0.54     11627\n",
      "\n",
      "   micro avg       0.58      0.58      0.58     24419\n",
      "   macro avg       0.58      0.58      0.58     24419\n",
      "weighted avg       0.58      0.58      0.58     24419\n",
      "\n",
      "[[8180 4612]\n",
      " [5618 6009]]\n",
      "('AUC:', 0.6373888723670665)\n",
      "\n",
      "\n",
      "CPU times: user 6min 33s, sys: 3min 27s, total: 10min 1s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p5','p7'],['p9'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'logistic')\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p7,p9]\n",
    "\n",
    "- test = [p5]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.8522493351163735)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79     95873\n",
      "           1       0.88      0.89      0.88    170339\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    266212\n",
      "   macro avg       0.84      0.84      0.84    266212\n",
      "weighted avg       0.85      0.85      0.85    266212\n",
      "\n",
      "[[ 76127  19746]\n",
      " [ 19587 150752]]\n",
      "('AUC:', 0.9183215137031264)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.855288266494373)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77     95873\n",
      "           1       0.83      0.97      0.90    170339\n",
      "\n",
      "   micro avg       0.86      0.86      0.86    266212\n",
      "   macro avg       0.87      0.81      0.83    266212\n",
      "weighted avg       0.86      0.86      0.85    266212\n",
      "\n",
      "[[ 63157  32716]\n",
      " [  5808 164531]]\n",
      "('AUC:', 0.8370564906246806)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.8524521809685514)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80     95873\n",
      "           1       0.89      0.88      0.88    170339\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    266212\n",
      "   macro avg       0.84      0.84      0.84    266212\n",
      "weighted avg       0.85      0.85      0.85    266212\n",
      "\n",
      "[[ 77291  18582]\n",
      " [ 20697 149642]]\n",
      "('AUC:', 0.9233206096056731)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.8533123976379727)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76     95873\n",
      "           1       0.83      0.97      0.89    170339\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    266212\n",
      "   macro avg       0.87      0.81      0.83    266212\n",
      "weighted avg       0.86      0.85      0.85    266212\n",
      "\n",
      "[[ 62426  33447]\n",
      " [  5603 164736]]\n",
      "('AUC:', 0.8481437839537317)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n",
      "('Accuracy:', 0.5323862675460849)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.84      0.56      6400\n",
      "         1.0       0.80      0.36      0.50     11339\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     17739\n",
      "   macro avg       0.61      0.60      0.53     17739\n",
      "weighted avg       0.66      0.53      0.52     17739\n",
      "\n",
      "[[5375 1025]\n",
      " [7270 4069]]\n",
      "('AUC:', 0.7907560466090484)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.6314335644624838)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.58      0.53      6400\n",
      "         1.0       0.73      0.66      0.70     11339\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     17739\n",
      "   macro avg       0.61      0.62      0.61     17739\n",
      "weighted avg       0.65      0.63      0.64     17739\n",
      "\n",
      "[[3689 2711]\n",
      " [3827 7512]]\n",
      "('AUC:', 0.7123665143531175)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.3689046733186764)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      1.00      0.53      6400\n",
      "         1.0       0.97      0.01      0.03     11339\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     17739\n",
      "   macro avg       0.67      0.51      0.28     17739\n",
      "weighted avg       0.75      0.37      0.21     17739\n",
      "\n",
      "[[ 6395     5]\n",
      " [11190   149]]\n",
      "('AUC:', 0.8356270669812151)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.6419189356784486)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.56      0.53      6400\n",
      "         1.0       0.73      0.69      0.71     11339\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     17739\n",
      "   macro avg       0.62      0.62      0.62     17739\n",
      "weighted avg       0.65      0.64      0.65     17739\n",
      "\n",
      "[[3556 2844]\n",
      " [3508 7831]]\n",
      "('AUC:', 0.7145214111694154)\n",
      "\n",
      "\n",
      "CPU times: user 7min 28s, sys: 3min 52s, total: 11min 21s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p7','p9'],['p5'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'logistic')\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration:\n",
    "- dataset = ['smooth','window']\n",
    "\n",
    "- split = 0\n",
    "\n",
    "- train = [p5,p9]\n",
    "\n",
    "- test = [p7]\n",
    "\n",
    "- includex = [0,0.2]\n",
    "\n",
    "- features = ['all']\n",
    "\n",
    "- prepocessing = ['standard','no']\n",
    "\n",
    "- Algorithm = Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smooth', 0, 'standard')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:98: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/bala/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:99: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.8215807351550736)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81    173189\n",
      "           1       0.78      0.89      0.83    169487\n",
      "\n",
      "   micro avg       0.82      0.82      0.82    342676\n",
      "   macro avg       0.83      0.82      0.82    342676\n",
      "weighted avg       0.83      0.82      0.82    342676\n",
      "\n",
      "[[131273  41916]\n",
      " [ 19224 150263]]\n",
      "('AUC:', 0.9025424082767256)\n",
      "\n",
      "\n",
      "('smooth', 0, 'no')\n",
      "('Accuracy:', 0.7536419241499259)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71    173189\n",
      "           1       0.69      0.91      0.79    169487\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    342676\n",
      "   macro avg       0.78      0.76      0.75    342676\n",
      "weighted avg       0.78      0.75      0.75    342676\n",
      "\n",
      "[[103710  69479]\n",
      " [ 14942 154545]]\n",
      "('AUC:', 0.8300288952101154)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'standard')\n",
      "('Accuracy:', 0.826646745030291)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82    173189\n",
      "           1       0.80      0.87      0.83    169487\n",
      "\n",
      "   micro avg       0.83      0.83      0.83    342676\n",
      "   macro avg       0.83      0.83      0.83    342676\n",
      "weighted avg       0.83      0.83      0.83    342676\n",
      "\n",
      "[[136363  36826]\n",
      " [ 22578 146909]]\n",
      "('AUC:', 0.907347195836216)\n",
      "\n",
      "\n",
      "('smooth', 0.2, 'no')\n",
      "('Accuracy:', 0.7864776056683281)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76    173189\n",
      "           1       0.73      0.91      0.81    169487\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    342676\n",
      "   macro avg       0.81      0.79      0.78    342676\n",
      "weighted avg       0.81      0.79      0.78    342676\n",
      "\n",
      "[[115252  57937]\n",
      " [ 15232 154255]]\n",
      "('AUC:', 0.8514780294902078)\n",
      "\n",
      "\n",
      "('window', 0, 'standard')\n",
      "('Accuracy:', 0.8368222825610931)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.78      0.83     11549\n",
      "         1.0       0.80      0.89      0.84     11285\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     22834\n",
      "   macro avg       0.84      0.84      0.84     22834\n",
      "weighted avg       0.84      0.84      0.84     22834\n",
      "\n",
      "[[ 9019  2530]\n",
      " [ 1196 10089]]\n",
      "('AUC:', 0.9187956016269873)\n",
      "\n",
      "\n",
      "('window', 0, 'no')\n",
      "('Accuracy:', 0.6883156696154856)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.47      0.60     11549\n",
      "         1.0       0.63      0.92      0.74     11285\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     22834\n",
      "   macro avg       0.74      0.69      0.67     22834\n",
      "weighted avg       0.74      0.69      0.67     22834\n",
      "\n",
      "[[ 5386  6163]\n",
      " [  954 10331]]\n",
      "('AUC:', 0.7281185101273137)\n",
      "\n",
      "\n",
      "('window', 0.2, 'standard')\n",
      "('Accuracy:', 0.8480336340544802)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.83      0.85     11549\n",
      "         1.0       0.83      0.87      0.85     11285\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     22834\n",
      "   macro avg       0.85      0.85      0.85     22834\n",
      "weighted avg       0.85      0.85      0.85     22834\n",
      "\n",
      "[[9539 2010]\n",
      " [1460 9825]]\n",
      "('AUC:', 0.9252418534684118)\n",
      "\n",
      "\n",
      "('window', 0.2, 'no')\n",
      "('Accuracy:', 0.5068757116580538)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.06      0.10     11549\n",
      "         1.0       0.50      0.97      0.66     11285\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     22834\n",
      "   macro avg       0.57      0.51      0.38     22834\n",
      "weighted avg       0.57      0.51      0.38     22834\n",
      "\n",
      "[[  645 10904]\n",
      " [  356 10929]]\n",
      "('AUC:', 0.6328624930479608)\n",
      "\n",
      "\n",
      "CPU times: user 6min 35s, sys: 3min 25s, total: 10min\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in ['smooth','window']:\n",
    "    for includex in [0,0.2]:\n",
    "            for preprocessing in ['standard','no']:\n",
    "                print(dataset,includex,preprocessing)\n",
    "                X_train, X_test, y_train, y_test = prepare_data(dataset,0,['p5','p9'],['p7'],includex,'all',preprocessing)\n",
    "                model(X_train, X_test, y_train, y_test,'logistic')\n",
    "                print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
